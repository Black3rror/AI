{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_char_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPyQY1nA2Y5qJYcbLYxbvIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Black3rror/AI/blob/master/Playground/Mini_char_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tVwFE_D2lH3"
      },
      "source": [
        "# Goal\n",
        "To implement a vanilla RNN with just a few lines of code (and just using numpy). This is almost a copy of what Andrej Karphathy have done at [this link](https://gist.github.com/karpathy/d4dee566867f8291f086).\\\n",
        "The task is learning to write a text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCMka-6Et7b3"
      },
      "source": [
        "![RNN - Copy.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ80H0dKAOGp"
      },
      "source": [
        "# Importing stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkUlKYIT7fid"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp2jx__ThfJY"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBcHzCfRmYZJ"
      },
      "source": [
        "\"\"\"\n",
        "@param X_batch, y_batch: seq_len one-hot array\n",
        "@param params: Wxh, Whh, Why, bh, by\n",
        "@return last_h: last hidden state\n",
        "#return dparams: dWxh, dWhh, dWhy, dbh, dby\n",
        "      shapes\n",
        "------------------\n",
        "X_batch: (seq_len, chars)\n",
        "y_batch: (seq_len, chars)\n",
        "h_prev:  (h_units, 1)\n",
        "\n",
        "h: (seq_len+1, h_units, 1) list\n",
        "y: (seq_len, chars, 1) list\n",
        "p: (seq_len, chars, 1) list\n",
        "\n",
        "Wxh: (chars, h_units)\n",
        "Whh: (h_units, h_units) (prev, current)\n",
        "Why: (h_units, chars)\n",
        "bh:  (h_units, 1)\n",
        "by:  (chars, 1)\n",
        "\n",
        "dy:  (chars, 1)\n",
        "dWxh: (chars, h_units)\n",
        "dWhh: (h_units, h_units) (prev, current)\n",
        "dWhy: (h_units, chars)\n",
        "dbh:  (h_units, 1)\n",
        "dby:  (chars, 1)\n",
        "dh:   (h_units, 1)\n",
        "\"\"\"\n",
        "def train_rnn(X_batch, y_batch, h_prev, params):\n",
        "  assert X_batch.ndim == 2\n",
        "  assert X_batch.shape == y_batch.shape\n",
        "  assert h_prev.ndim == 2\n",
        "  assert h_prev.shape[1] == 1\n",
        "  # forward path\n",
        "  h = {}\n",
        "  y = {}\n",
        "  p = {}\n",
        "  batch_loss =  0\n",
        "\n",
        "  Wxh, Whh, Why, bh, by = params\n",
        "\n",
        "  h[-1] = h_prev\n",
        "  for t in range(len(X_batch)):\n",
        "    h[t] = np.tanh(np.dot(Wxh.T, X_batch[t].reshape(-1, 1)) + \n",
        "                   np.dot(Whh.T, h[t-1]) + bh)\n",
        "    y[t] = np.dot(Why.T, h[t]) + by\n",
        "    p[t] = np.exp(y[t]) / np.sum(np.exp(y[t]))\n",
        "    batch_loss += -np.log(p[t][y_batch[t] == 1])\n",
        "  \n",
        "  batch_loss /= len(X_batch)\n",
        "\n",
        "  # backward path\n",
        "  dWxh = np.zeros_like(Wxh)\n",
        "  dWhh = np.zeros_like(Whh)\n",
        "  dWhy = np.zeros_like(Why)\n",
        "  dbh = np.zeros_like(bh)\n",
        "  dby = np.zeros_like(by)\n",
        "\n",
        "  dh_next = 0\n",
        "  for t in reversed(range(len(X_batch))):\n",
        "    dy = p[t].copy()\n",
        "    dy[y_batch[t] == 1] -= 1\n",
        "    dWhy += np.dot(h[t], dy.T)\n",
        "    dby += dy\n",
        "    dh = np.dot(Why, dy) + dh_next\n",
        "    dh = dh * (1 - h[t]**2)\n",
        "    dWhh += np.dot(h[t-1], dh.T)\n",
        "    dbh += dh\n",
        "    dWxh += np.dot(X_batch[t].reshape(-1, 1), dh.T)\n",
        "    dh_next = np.dot(Whh, dh)\n",
        "    \n",
        "  dparams = dWxh, dWhh, dWhy, dbh, dby\n",
        "  for dparam in dparams:\n",
        "    np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
        "  \n",
        "  last_h = h[len(X_batch)-1]\n",
        "  assert last_h.shape == h_prev.shape\n",
        "  return last_h, dparams, batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-wDDTtDhqgw"
      },
      "source": [
        "\"\"\"\n",
        "@param x: first character, one-hot array\n",
        "@param params: Wxh, Whh, Why, bh, by\n",
        "@return new_text: an array containing one-hot representation of the text\n",
        "      shapes\n",
        "------------------\n",
        "x: (chars, 1)\n",
        "h: (h_units, 1)\n",
        "\n",
        "y: (chars, 1)\n",
        "p: (chars, 1)\n",
        "\n",
        "Wxh: (chars, h_units)\n",
        "Whh: (h_units, h_units) (prev, current)\n",
        "Why: (h_units, chars)\n",
        "bh:  (h_units, 1)\n",
        "by:  (chars, 1)\n",
        "\"\"\"\n",
        "def create_text(x, h, params, len):\n",
        "  assert x.ndim == 2\n",
        "  assert h.ndim == 2\n",
        "  assert x.shape[1] == 1\n",
        "  assert h.shape[1] == 1\n",
        "  Wxh, Whh, Why, bh, by = params\n",
        "  new_text = np.zeros((len, x.shape[0]))\n",
        "  new_text[0] = x.reshape(-1)\n",
        "  for t in range(1, len):\n",
        "    h = np.tanh(np.dot(Wxh.T, x) + np.dot(Whh.T, h) + bh)\n",
        "    y = np.dot(Why.T, h) + by\n",
        "    p = np.exp(y) / np.sum(np.exp(y))\n",
        "    indx = np.random.choice(range(x.shape[0]), p=p.ravel())\n",
        "    x = np.zeros_like(x)\n",
        "    x[indx] = 1\n",
        "    new_text[t] = x.reshape(-1)\n",
        "  return new_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiVonDr26nde"
      },
      "source": [
        "\"\"\"\n",
        "@param x: list of characters\n",
        "@return y: array of one-hot representation\n",
        "\"\"\"\n",
        "def char_to_hot(x, chars):\n",
        "  y = np.zeros((len(x), len(chars)))\n",
        "  char_to_indx = { ch:i for i,ch in enumerate(chars) }\n",
        "  for i in range(len(x)):\n",
        "    y[i, char_to_indx[x[i]]] = 1\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ8gVSHs_WMp"
      },
      "source": [
        "\"\"\"\n",
        "@param x: array of one-hot representation\n",
        "@return y: list of characters\n",
        "\"\"\"\n",
        "def hot_to_char(x, chars):\n",
        "  indx_to_char = { i:ch for i,ch in enumerate(chars) }\n",
        "  indxs = np.argmax(x, axis = 1)\n",
        "  y = []\n",
        "  for i in range(len(x)):\n",
        "    y.append(indx_to_char[indxs[i]])\n",
        "  return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sditQLtn4dFb"
      },
      "source": [
        "def flat_params(params):\n",
        "  Wxh, Whh, Why, bh, by = params\n",
        "  params_flat = Wxh.reshape(-1)\n",
        "  params_flat = np.concatenate((params_flat, Whh.reshape(-1), Why.reshape(-1),\n",
        "                                bh.reshape(-1), by.reshape(-1)))\n",
        "  return params_flat.reshape(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tumbcmh5QxF"
      },
      "source": [
        "def reshape_params(params_flat, params_sample):\n",
        "  p0, p1 = 0, 0\n",
        "  params = []\n",
        "  for i in range(5):\n",
        "    p0 = p1\n",
        "    p1 = p1 + np.prod(params_sample[i].shape)\n",
        "    params.append(params_flat[p0:p1].reshape(params_sample[i].shape))\n",
        "  return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W60Yv1Bu6dm"
      },
      "source": [
        "class Adagrad():\n",
        "  def __init__(self, learning_rate = 0.1, beta = 0.999, step = 1, epsilon = 1e-7):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.beta = beta\n",
        "    self.step = step\n",
        "    self.epsilon = epsilon\n",
        "    self.moment = None\n",
        "  \n",
        "  \"\"\"\n",
        "        shapes\n",
        "  ------------------\n",
        "  vars:         (vars, 1)\n",
        "  grads:        (vars, 1)\n",
        "  vars_changes: (vars, 1)\n",
        "  \"\"\"\n",
        "  def __call__(self, vars, grads, step = None):\n",
        "    assert len(vars.shape) == 2\n",
        "    assert vars.shape[1] == 1\n",
        "    assert vars.shape == grads.shape\n",
        "    if isinstance(step, int):\n",
        "      self.step = step\n",
        "    \n",
        "    vars_changes = self.compute_changes(grads)\n",
        "    return vars + vars_changes\n",
        "  \n",
        "  \"\"\"\n",
        "  @brief computes the amount changes needed to optimize variables\n",
        "        shapes\n",
        "  ------------------\n",
        "  grads:        (vars, 1)\n",
        "  changes: (vars, 1)\n",
        "  \"\"\"\n",
        "  def compute_changes(self, grads, step = None):\n",
        "    if self.moment is None:\n",
        "      self.moment = np.zeros_like(grads)\n",
        "\n",
        "    assert self.moment.shape == grads.shape\n",
        "    \n",
        "    if isinstance(step, int):\n",
        "      self.step = step\n",
        "\n",
        "    self.moment = self.beta * self.moment + (1 - self.beta) * grads * grads\n",
        "    moment_unbiased = self.moment / (1 - self.beta ** self.step)\n",
        "\n",
        "    # Adagrad\n",
        "    changes = - self.learning_rate * grads / (np.sqrt(moment_unbiased + self.epsilon))\n",
        "    return changes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HZ2TyFwAR30"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItLPDbZ88pnw",
        "outputId": "dee92b61-3fed-4109-d01c-cc6c4c72236a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "h_units = 100\n",
        "seq_len = 25\n",
        "learning_rate = 1e-1\n",
        "epochs = 10\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "text_adrs = '/content/drive/My Drive/Colab Stuff/Mini_char_RNN/William Shakespear.txt'\n",
        "\n",
        "text = open(text_adrs, 'r').read()\n",
        "chars = sorted(list(set(text)))\n",
        "print(\"text has %d characters, %d unique.\" % (len(text), len(chars)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "text has 5558552 characters, 107 unique.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEHRuPuL0_XF"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCQLryX2zLpZ",
        "outputId": "8ca36613-f840-4db4-ff03-623f74d2f2a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Wxh = np.random.randn(len(chars), h_units) * 0.01\n",
        "Whh = np.random.randn(h_units, h_units) * 0.01\n",
        "Why = np.random.randn(h_units, len(chars)) * 0.01\n",
        "bh = np.zeros((h_units, 1))\n",
        "by = np.zeros((len(chars), 1))\n",
        "\n",
        "gen_freq = 1000\n",
        "smooth_loss = 0\n",
        "step = 0\n",
        "\n",
        "optimizer = Adagrad(learning_rate)\n",
        "\n",
        "for epoch_num in range(epochs):\n",
        "  print(\"epoch %d started --------------------------\" % epoch_num)\n",
        "  h = np.zeros((h_units, 1))\n",
        "\n",
        "  for pointer in range(0, len(text)-seq_len-1, seq_len):\n",
        "    step += 1\n",
        "\n",
        "    X_batch = text[pointer:pointer+seq_len]\n",
        "    y_batch = text[pointer+1:pointer+1+seq_len]\n",
        "    X_batch = char_to_hot(X_batch, chars)\n",
        "    y_batch = char_to_hot(y_batch, chars)\n",
        "    params = Wxh, Whh, Why, bh, by\n",
        "    h, dparams, batch_loss = train_rnn(X_batch, y_batch, h, params)\n",
        "\n",
        "    smooth_loss = 0.999 * smooth_loss + 0.001 * batch_loss\n",
        "\n",
        "    params_flat = flat_params(params)\n",
        "    dparams_flat = flat_params(dparams)\n",
        "    params_flat = optimizer(params_flat, dparams_flat)\n",
        "    params = reshape_params(params_flat, params)\n",
        "    Wxh, Whh, Why, bh, by = params\n",
        "\n",
        "    gen_freq -= 1\n",
        "    if gen_freq == 0:\n",
        "      start_hot = char_to_hot([text[pointer]], chars).T\n",
        "      new_text = create_text(start_hot, h, params, 100)\n",
        "      new_text = hot_to_char(new_text, chars)\n",
        "      new_text_str = \"\"\n",
        "      new_text_str = new_text_str.join(new_text)\n",
        "      print(\"\\n\\nstep %d: smooth_loss = %.4f\" % (step, smooth_loss))\n",
        "      print(\"new text: \", new_text_str)\n",
        "      gen_freq = 1000 + int(10*np.random.rand())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 started --------------------------\n",
            "\n",
            "\n",
            "step 1000: smooth_loss = 2.0197\n",
            "new text:  nt cin ae0 piv mteebiolae b nlaubp,\n",
            "Dg ce lseLeud es\n",
            "\n",
            "The ane\tphed sane ne, theinhe , ore nkomn \n",
            " ta\n",
            "\n",
            "\n",
            "step 2009: smooth_loss = 2.3565\n",
            "new text:  h  Tan this thel,  hase thoxg fhane, foran eod  dith binh lare oth be chrthirtd riat hr mol sherd th\n",
            "\n",
            "\n",
            "step 3011: smooth_loss = 2.3759\n",
            "new text:  kluhde, pirylingad lor dak erer’t neawilRe, uy oike,\n",
            "Dar lol toraYmeu3g ne aniny atemaje moD noit th\n",
            "\n",
            "\n",
            "step 4013: smooth_loss = 2.3146\n",
            "new text:  rth na seil breit ney tho cas corespidcis dill thath a nltcinds thy of woid,\n",
            "mrath erce sho hat whas\n",
            "\n",
            "\n",
            "step 5015: smooth_loss = 2.4566\n",
            "new text:  As tnomont;angnght;\n",
            " yot.\n",
            "ST]ay. m thay Thak anr ret.Tnom cole I thot dove.\n",
            "AW be, on nou sov me;?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "step 6023: smooth_loss = 2.4207\n",
            "new text:  ut.\n",
            "You erave and ernnat eer, Yom stilaen,\n",
            "I ge yive foring anl ast and or, bowdalp’s.\n",
            "\n",
            "Win. IW amo \n",
            "\n",
            "\n",
            "step 7024: smooth_loss = 2.3692\n",
            "new text:  ; dirise’s whed te ery wolos Furgile histe she hand for’sesraid engevince cice whe the wieln, I sfoo\n",
            "\n",
            "\n",
            "step 8027: smooth_loss = 2.3326\n",
            "new text:   hith\n",
            "Bes this:\n",
            "I not yos, bamy bef\n",
            "Alat bat:\n",
            "Whed’mis. h. [rofu,\n",
            "Aert therill! vef wivklven:\n",
            "\n",
            "CLESR\n",
            "\n",
            "\n",
            "step 9029: smooth_loss = 2.3068\n",
            "new text:  \n",
            "Pat ine meaut wive riss your I siotar thotearde whest hin. t; intaveir, shelrt, dor er k]ss mer gro\n",
            "\n",
            "\n",
            "step 10032: smooth_loss = 2.3917\n",
            "new text:  ’w\n",
            " anf stload\n",
            "Andie.\n",
            "\n",
            "SMAROORAY.\n",
            "The at ton qungtent. I is an pay pom, hord sand\n",
            "Whe peay, evay tTE\n",
            "\n",
            "\n",
            "step 11035: smooth_loss = 2.3606\n",
            "new text:  OUS.\n",
            "I hathfus, oud?\n",
            "ANTA Eshid dide\n",
            "OM do net ate the woveresrean how thout id of lof oupuauRand he\n",
            "\n",
            "\n",
            "step 12041: smooth_loss = 2.3061\n",
            "new text:  atus, hair.\n",
            "\n",
            "Erach and baumin Lonk wis duenau it dae and ’e’cu hath’s prowh caw mes panumesice ryipi\n",
            "\n",
            "\n",
            "step 13048: smooth_loss = 2.3043\n",
            "new text:  \n",
            "La_ghs stird Ord’sigers;\n",
            "Beer theaPlen. Xut her artr on ledas to thichtild\n",
            "Hat simreis lean’d don a\n",
            "\n",
            "\n",
            "step 14056: smooth_loss = 2.2873\n",
            "new text:  SPIENR.\n",
            "\n",
            "T Enthy her; mimy for buf, wicl te theu rerxath youk thou.\n",
            "Hmear sond thasm by beraks set g\n",
            "\n",
            "\n",
            "step 15064: smooth_loss = 2.2760\n",
            "new text:  ygsalut oo los I oult’ves ind\n",
            "She is fare nunce be bust cluis wand.\n",
            "\n",
            "CLEOPABLAR.\n",
            "Ang se a tise fout \n",
            "\n",
            "\n",
            "step 16073: smooth_loss = 2.2829\n",
            "new text:  shot'kstss  at o qull shy witg! I hof; indamis o score. Hurnuinut an this wo culath I coed leall wis\n",
            "\n",
            "\n",
            "step 17076: smooth_loss = 2.2240\n",
            "new text:  rall a nofiam, I fape nto,\n",
            "I I shy Jor by mer wenot fordenre.\n",
            " Ouly,\n",
            "    I gor botyl.\n",
            "  SI I  FOm! I\n",
            "\n",
            "\n",
            "step 18077: smooth_loss = 2.1390\n",
            "new text:   olrist and bingly, held gorfull'der\n",
            "     Letealk buczaun,\n",
            "  ONINTONE.\n",
            "  Efor and foming papan'.\n",
            "  w\n",
            "\n",
            "\n",
            "step 19084: smooth_loss = 2.1157\n",
            "new text:   not? OtADIt hat of food sa tho. Jot her thut spepate, urd! [o  id, sht und itst lijaty pull\n",
            "    No \n",
            "\n",
            "\n",
            "step 20086: smooth_loss = 2.0670\n",
            "new text:   thing cor, how sshalife abenten wor womonliime bled und or dise,\n",
            "    eert; Ie ughian wist she youl,\n",
            "\n",
            "\n",
            "step 21090: smooth_loss = 2.1511\n",
            "new text:  ont encue\n",
            "Hnos, sorr. Ishirggare,\n",
            "My hemeevod;\n",
            "Darighiop themsio wipherover mered,\n",
            "Fis sos,\n",
            "OSALAFAn\n",
            "\n",
            "\n",
            "step 22096: smooth_loss = 2.1051\n",
            "new text:  r IUCUS SURAROE.\n",
            "I yuld feom, ot.\n",
            "I wivgrfe am eswroath a hithirgurece sear ind, is thou hall fand\n",
            " \n",
            "\n",
            "\n",
            "step 23103: smooth_loss = 2.0428\n",
            "new text:  t, yo, digfer, ’ire, mavelare food sindeting cas holling\n",
            "The thato or nowe, pror ong bum tomel mor b\n",
            "\n",
            "\n",
            "step 24112: smooth_loss = 2.0737\n",
            "new text:   her you, do my gune a levild deed the hiile cece digher wel wald,\n",
            "I he whalcg weld ind, samdr he ph\n",
            "\n",
            "\n",
            "step 25120: smooth_loss = 2.1536\n",
            "new text:  ne.    sworco, cow uchowed mes you bep he,\n",
            "    not of     bis yeog,\n",
            "    tand In bondice jue ip have \n",
            "\n",
            "\n",
            "step 26124: smooth_loss = 2.1277\n",
            "new text:  it and thavas, herell eld it pall gowle i. SEMINIUS. nth lil saler tod\n",
            "              fas snow hove d\n",
            "\n",
            "\n",
            "step 27125: smooth_loss = 2.0902\n",
            "new text:   wheip they, nifser the to catoon to nie yis dyake gor; and wireng wow efigry the seray'd. I onl he'\n",
            "\n",
            "\n",
            "step 28125: smooth_loss = 2.0197\n",
            "new text:   they ithfle, but erh ans, thor high'fe munce hem bnsize forld\n",
            "   Hny oun susren orfior besus; Whis \n",
            "\n",
            "\n",
            "step 29126: smooth_loss = 1.9892\n",
            "new text:   she laviched thet sorm; my heest. You got nibnod bet Rone and noute, detean sis fop han say.\n",
            "      \n",
            "\n",
            "\n",
            "step 30134: smooth_loss = 1.9903\n",
            "new text:  timicizels? His! Whith ou wither'd a'd,\n",
            "    Hifuss\n",
            "            you lowd to we hid pist honed beare w\n",
            "\n",
            "\n",
            "step 31142: smooth_loss = 2.0054\n",
            "new text:  A gent\n",
            "   Whe wive frot nou cided\n",
            "     Amkeakiepar you\n",
            "                               hith frorot of\n",
            "\n",
            "\n",
            "step 32151: smooth_loss = 2.1629\n",
            "new text:   ous heacie.\n",
            "\n",
            "IMOGEN.\n",
            "O meadt havge moene ough, hor shang I hing, hor to halk cold hinl ir of Phanva\n",
            "\n",
            "\n",
            "step 33157: smooth_loss = 2.1892\n",
            "new text:  h afec’d wak’f, ampherth prace, flag kad keran fon, here mponk’d efafirivesope ham, cros o’T T’TCOGE\n",
            "\n",
            "\n",
            "step 34163: smooth_loss = 2.2038\n",
            "new text:   arjat haere col pra!m asald, is fufch, lorsicd all’d, hedtull peats,\n",
            "(hich lat sho afm, truld Ielia\n",
            "\n",
            "\n",
            "step 35171: smooth_loss = 2.1945\n",
            "new text:  hen. [_lerpeis.’nder, siveans btear I bawstale rvasss’s\n",
            "A sher’d fres mlieandel moveghell sela a us \n",
            "\n",
            "\n",
            "step 36172: smooth_loss = 2.1779\n",
            "new text:  u, so mastis lerel mnfeinder; I thene; that.\n",
            "Thy momemI’’ dyy, a sas fefurd the grigh, lurt\n",
            "fas detb\n",
            "\n",
            "\n",
            "step 37172: smooth_loss = 2.2079\n",
            "new text:  esnsts freiraelissss leinsh: nou of srron knier unstdindere; utichihing nooliar! you, nroulf wid you\n",
            "\n",
            "\n",
            "step 38178: smooth_loss = 2.2023\n",
            "new text:  il andfen, the whomin’ roobod wiid to Hath the.\n",
            "Hantarher.\n",
            "\n",
            "\n",
            "MARATLUR.\n",
            "Thind\n",
            "Thy vis the spour sas r\n",
            "\n",
            "\n",
            "step 39184: smooth_loss = 2.1810\n",
            "new text:  t.\n",
            "\n",
            "MARCLEMIA.\n",
            "Wofar;\n",
            "Hyurin’d sorm toniin’s henm\n",
            "Lakendcicy\n",
            "Hers her,\n",
            "forn wheam and hexyotis frain\n",
            "\n",
            "\n",
            "step 40191: smooth_loss = 2.1534\n",
            "new text:  e.\n",
            "\n",
            "KING.\n",
            "\n",
            "As ead tisd, I pard; sous ande, me?, bor bimest fon os fad you reld.\n",
            "\n",
            "PING.\n",
            "Mfen, to sas \n",
            "\n",
            "\n",
            "step 41192: smooth_loss = 2.1577\n",
            "new text:  . \n",
            "HAMLET.\n",
            "Gowest ve puncme bonton.\n",
            "\n",
            "HAMLET.\n",
            " Hithie\n",
            "bey my to seeveruchem?\n",
            "Ort,\n",
            "A o him\n",
            "Hoomse. I h\n",
            "\n",
            "\n",
            "step 42192: smooth_loss = 2.1316\n",
            "new text:  h foull sut be hean bants I’ll cay. Ord!\n",
            "\n",
            " [_ dorom._]\n",
            " Of and hen.\n",
            "A the in the venat.\n",
            "Wer! Monnass\n",
            "\n",
            "\n",
            "step 43199: smooth_loss = 2.1213\n",
            "new text:  st more, pran hiter shavins.\n",
            "\n",
            "SCELID Thereres, that te, berrelomst\n",
            "Asten.\n",
            "\n",
            "KINILb.\n",
            "Wonreciak is pess\n",
            "\n",
            "\n",
            "step 44205: smooth_loss = 2.0917\n",
            "new text:  idly noo muy,\n",
            "I whos beifn’s the svor on that lor of mans and os\n",
            "Wre\n",
            "Wing th’m\n",
            "Woy.\n",
            "\n",
            "HAMLWAMO. A’d t\n",
            "\n",
            "\n",
            "step 45211: smooth_loss = 2.1376\n",
            "new text:   vilkiell lind sur; cuarasershice is this dess, shed\n",
            "Heraturr ubl._]\n",
            "\n",
            "At Dftring fealhy, Mine,\n",
            "Fousi\n",
            "\n",
            "\n",
            "step 46213: smooth_loss = 2.1897\n",
            "new text:  tiy kist ancow!\n",
            "\n",
            "WORTE.\n",
            "Sout to yorter tha, prirgufry so uers.\n",
            "\n",
            "WORCOS.\n",
            "Anots!\n",
            "Nyue—\n",
            "Wall!—An’cont t\n",
            "\n",
            "\n",
            "step 47213: smooth_loss = 2.1910\n",
            "new text:   dean a\n",
            "Uhen so tude Idlest, he thee But sir mud whe sthouster:\n",
            "Whe thete; I hild sirce it:—Frond Ju\n",
            "\n",
            "\n",
            "step 48219: smooth_loss = 2.1582\n",
            "new text:  ras fouf of epods he dord him\n",
            "A man frun trom and his hery!\n",
            "And whou your frike with awarhacher\n",
            "A he\n",
            "\n",
            "\n",
            "step 49221: smooth_loss = 2.1543\n",
            "new text:  tf-derrique fugrs fasite; Wire\n",
            "Thour wead ol in affore, and in vood be the fort a kise our all of as\n",
            "\n",
            "\n",
            "step 50223: smooth_loss = 2.1564\n",
            "new text:   ond that\n",
            "The wish whan tay tercue not shous yusbbes buset o wet mes,\n",
            "Aurt the but.\n",
            "What donsworor W\n",
            "\n",
            "\n",
            "step 51228: smooth_loss = 2.1962\n",
            "new text:  I ac-crid' iom dyod sare alddes ins seforg-ery-his the-doon HLensk uses\n",
            "     ENqure\n",
            "    to betunoune\n",
            "\n",
            "\n",
            "step 52234: smooth_loss = 2.1382\n",
            "new text:  gu?\n",
            "   fough rotun they than had the lat the grom it the nit on stlinch my wous limsly, dead\n",
            "     Kt\n",
            "\n",
            "\n",
            "step 53242: smooth_loss = 2.0945\n",
            "new text:    'roul bons, and mars tith           anden fave retton ie Iilt, mor shee!  [Exein. So penalrenren; \n",
            "\n",
            "\n",
            "step 54242: smooth_loss = 2.0261\n",
            "new text:  th So moth a covcakis, shaston,\n",
            "   Sear-culdt she hop, hoth\n",
            "    hee shew.\n",
            "  FyUL. Whe hean?\n",
            "      Ex\n",
            "\n",
            "\n",
            "step 55247: smooth_loss = 1.9958\n",
            "new text:  o and     Deand of me. Af you I and rort Jakce lele you, yup, nery eitly, I deae that aret.\n",
            "  DOIND \n",
            "\n",
            "\n",
            "step 56247: smooth_loss = 1.9813\n",
            "new text:  s in wald unvaw; olninged.\n",
            "  MIND JINCE SCRBLK. My Jomerodmgresor' forilsingaly welloroagks, sich wh\n",
            "\n",
            "\n",
            "step 57254: smooth_loss = 1.9755\n",
            "new text:  ingtelle. Gon yiv JUNS. I and rod streft I, Jore ford you faice the colg. Gimpne no.  PRINCENbe eelt\n",
            "\n",
            "\n",
            "step 58255: smooth_loss = 2.1156\n",
            "new text:   in Fre bed, aat in of there chst readed; brech sile\n",
            "Ufrichy\n",
            "the no filih ble angan tobings,\n",
            "Forfiaf\n",
            "\n",
            "\n",
            "step 59256: smooth_loss = 2.1439\n",
            "new text:  of friqe bolr lold hall crop and och frow did,\n",
            "snos cothinc. If sigrt.\n",
            "\n",
            "\n",
            "KAge all of himrst thy rind\n",
            "\n",
            "\n",
            "step 60265: smooth_loss = 2.1898\n",
            "new text:  m.\n",
            "Griscs his lod theem it offereshing my food\n",
            "puncord-Rive shim win kleicriaghter,\n",
            "Use of them his \n",
            "\n",
            "\n",
            "step 61269: smooth_loss = 2.1074\n",
            "new text:  menty, ploarler that then! I\n",
            "Pact the liilys Ero, falmatard neos pihe a blety.\n",
            "\n",
            "CING HENRY.\n",
            "Than the\n",
            "\n",
            "\n",
            "step 62278: smooth_loss = 2.1004\n",
            "new text:  sts.\n",
            "\n",
            "LIUF Kryherten?, o ran allay andian ansery.\n",
            "\n",
            "FLUELLEN.\n",
            "Hr as; knoves.\n",
            "\n",
            "OLLEAC.\n",
            "Sow\n",
            "\n",
            "FILLO EI\n",
            "M\n",
            "\n",
            "\n",
            "step 63286: smooth_loss = 2.0990\n",
            "new text:   and in hads.\n",
            "\n",
            "COY.\n",
            "Nol placky would hast are e scishs;\n",
            "then peach this thou ponth; Kis do\n",
            "is, GUk.\n",
            "\n",
            "\n",
            "\n",
            "step 64295: smooth_loss = 2.1524\n",
            "new text:  not me thingtt, the spilevyus matheny s toh tt I'll I'll out it ott; up thy OF Ore bass its, thee be\n",
            "\n",
            "\n",
            "step 65304: smooth_loss = 2.0440\n",
            "new text:  addsaldgemes'stry, ice\n",
            "     wae more's head that is before, to wasmaild is;\n",
            "    sersed dunet pargoug\n",
            "\n",
            "\n",
            "step 66310: smooth_loss = 2.0067\n",
            "new text:  und hathien ald ke on pricig:\n",
            "  Fonod s             As conctde keser feat, the spade         \n",
            "      \n",
            "\n",
            "\n",
            "step 67314: smooth_loss = 1.9974\n",
            "new text:  loth wo hirsd rods hen.\n",
            "                                  Frare, leat prought,\n",
            "  EXA of Pidesgiontsi\n",
            "\n",
            "\n",
            "step 68314: smooth_loss = 1.9683\n",
            "new text:  toobdeded will of on\n",
            "              boft us to penciof, cond!\n",
            "      Enks morl your o poasd piold     \n",
            "\n",
            "\n",
            "step 69318: smooth_loss = 2.0300\n",
            "new text:  \n",
            "  BY, her.\n",
            "  SHE SOUF, SaLLY. Angadret;\n",
            " SUFK,\n",
            " And,\n",
            " wo SCEINLOUKKA SOUFJNAS, OWAS, SALK SUUFFERON\n",
            "\n",
            "\n",
            "step 70327: smooth_loss = 2.0065\n",
            "new text:  n and SURER. StaELE, Sloy thak nhat to as lur dempon bance the do yoMENGE KE GUFETTENELIETER. Art, m\n",
            "\n",
            "\n",
            "step 71332: smooth_loss = 1.9841\n",
            "new text:   hamrege is us vartetun.\n",
            "  SCEUCESSY. Than that of iw; my coumbanthatt.\n",
            "  SOPHESSETSIN. Sith wishors\n",
            "\n",
            "\n",
            "step 72335: smooth_loss = 1.9625\n",
            "new text:  un the than all are hy show with ther tham the gulk whourithauke for my noblinnen has loull haus loy\n",
            "\n",
            "\n",
            "step 73343: smooth_loss = 1.9303\n",
            "new text:  s.\n",
            "  SUFFUNG dure, have do to jess near's's hart,\n",
            "    And\n",
            "    UTiX For have a hith bearmaling\n",
            "    Wh\n",
            "\n",
            "\n",
            "step 74347: smooth_loss = 1.9764\n",
            "new text:   ankeal tayn anent; his, stink's diidn, it, cloused toot mant pise nom Jey lens to wrows.\n",
            "  CICK. So\n",
            "\n",
            "\n",
            "step 75352: smooth_loss = 1.9469\n",
            "new text:  \n",
            "  BUCOF. pee hangy areg buns wherf stess myay am a hif the all? Cecce all gake.\n",
            "  Wll a ware that y\n",
            "\n",
            "\n",
            "step 76355: smooth_loss = 1.9211\n",
            "new text:  e 'Dou utt'll and ie, ce.\n",
            "  WETTARWARAR.\n",
            "    Thy scoce; ood a dare saal\n",
            "    And.\n",
            "  KING HENRY. Toar \n",
            "\n",
            "\n",
            "step 77359: smooth_loss = 1.9135\n",
            "new text:  s, tour I our bungreroulk, rouns I buthee-to in rike, warws to Quack, liss bus to hing we kise my un\n",
            "\n",
            "\n",
            "step 78368: smooth_loss = 1.8868\n",
            "new text:  s fled love plk my And ondt,\n",
            "    In spay let beath.\n",
            "  RARWARD.\n",
            "  WICHARD Cut debple be'R shoult hind\n",
            "\n",
            "\n",
            "step 79369: smooth_loss = 1.8840\n",
            "new text:  it therws thee hose. By, a wimr of cramive I Lowne stralings love our iss than danrerw kink thee cai\n",
            "\n",
            "\n",
            "step 80369: smooth_loss = 1.8818\n",
            "new text:  rs hear to love to stard to moutak's is my noul,\n",
            " caro ie tas rose to to chams sreemor wOFO, HENTENT\n",
            "\n",
            "\n",
            "step 81373: smooth_loss = 1.8750\n",
            "new text:  m'lieod\n",
            "    The col os he thle kis lloatlass Jood;\n",
            "    The butow os have kingherser;\n",
            "Wllight limglat\n",
            "\n",
            "\n",
            "step 82375: smooth_loss = 1.9361\n",
            "new text:  h'd houmleigpiay ad to CLeimealan as a that you Parmor and pevy-' Encer at the as a tat Grad side th\n",
            "\n",
            "\n",
            "step 83383: smooth_loss = 1.9697\n",
            "new text:   I your the wrourt!\n",
            "  yORDY onelient.\n",
            "  CHAMSERD. Sa, of' sign'n. lay, cace the fard eibnont theands\n",
            "\n",
            "\n",
            "step 84385: smooth_loss = 1.9214\n",
            "new text:  ecte in telt.\n",
            "    cus not\n",
            "   OLINER]    Bun Bom' a wo he ucty may\n",
            "    Are fe; youkanny\n",
            "\n",
            "  As three c\n",
            "\n",
            "\n",
            "step 85388: smooth_loss = 1.9263\n",
            "new text:  ignt to a lingtiosthaund tgite ont\n",
            "    Strecktever him and to steate tOLKIRK.\n",
            "    An frie be\n",
            "    Hav\n",
            "\n",
            "\n",
            "step 86393: smooth_loss = 1.8976\n",
            "new text:   Coa;\n",
            "                                            \n",
            "  OLIN, swis. If.\n",
            "    ROLEY. Nich hes bveg and is\n",
            "\n",
            "\n",
            "step 87402: smooth_loss = 1.9102\n",
            "new text:   grier to homrer ylep fas out his a vear\n",
            " \n",
            "  Therer\n",
            "    As cray- \n",
            "  Kis thon?\n",
            "  GLOUC. Thy, with alk\n",
            "\n",
            "\n",
            "step 88404: smooth_loss = 1.9801\n",
            "new text:  on thair. Of the liad\n",
            "\n",
            "  Allis. The stard ell'chbour ou the h. DOK YREE\n",
            " HARN nou and ngun sout and \n",
            "\n",
            "\n",
            "step 89412: smooth_loss = 1.9419\n",
            "new text:  ffan'd.\n",
            "  CLANTTANLE.\n",
            "    Wh'r in and your surdive dain'd shal in notes uul, rungh upe,\n",
            "\n",
            "  KING JOHN\n",
            "\n",
            "\n",
            "step 90413: smooth_loss = 1.9263\n",
            "new text:  hy shighlings thos, and of Eller will all'd ordiers ung porthancistll bloy desen,\n",
            "    And a pork dig\n",
            "\n",
            "\n",
            "step 91421: smooth_loss = 1.9024\n",
            "new text:  ve for air thou of hevem-have outhoor whenf,\n",
            "    Af ent Af crow?\n",
            "  ARTHUP. Would I chiar hanthle,\n",
            "  \n",
            "\n",
            "\n",
            "step 92422: smooth_loss = 1.8944\n",
            "new text:  gh.\n",
            "    B, I do mort, am aff this\n",
            "    A thell right adirr'd robl apde, bllond\n",
            "    Frupcter milten, t\n",
            "\n",
            "\n",
            "step 93428: smooth_loss = 1.8881\n",
            "new text:   thuse\n",
            "       Arient\n",
            "    My Lows'd be oug hast Aght you strevendy out hear uuth mat is parker Foouss\n",
            "\n",
            "\n",
            "step 94436: smooth_loss = 2.0333\n",
            "new text:  As uping the,\n",
            "So arby to till. You them it, aveld soMUY.\n",
            "Castt praint take.\n",
            "Hentitionot it the mando\n",
            "\n",
            "\n",
            "step 95438: smooth_loss = 2.0389\n",
            "new text:  kent sore serdyals,\n",
            "And a nege.\n",
            "Yuurs a to my prart m nour oftoather Re as Ro aent, a sare the kly.\n",
            "\n",
            "\n",
            "\n",
            "step 96444: smooth_loss = 1.9847\n",
            "new text:  ; you midod him shall. Hoans be to Caes?\n",
            " CIUTIZN.\n",
            "Cads my llod?\n",
            "\n",
            "CETSAND.\n",
            "If thon bead go so enod,\n",
            "\n",
            "\n",
            "\n",
            "step 97450: smooth_loss = 1.9574\n",
            "new text:  o dids.\n",
            "\n",
            "LUCIUS.\n",
            "I shoult priight.fids our I dloy!\n",
            "\n",
            "BRSTAVI.\n",
            "Morn go but think?\n",
            "\n",
            "BRUTUS.\n",
            "I lid cicin\n",
            "\n",
            "\n",
            "step 98451: smooth_loss = 2.0251\n",
            "new text:  er by the miry iss me?\n",
            "\n",
            " [_A Hantt Alfurdt;\n",
            "I\n",
            "\n",
            "BRARELE.\n",
            "Honcrareer.\n",
            "Hear mard merorq,\n",
            "Ingente and my\n",
            "\n",
            "\n",
            "step 99452: smooth_loss = 2.0429\n",
            "new text:  O see.\n",
            "\n",
            "  OLA.\n",
            "Heep were the my bent that, my cose detiteost’d mee chare noblelnet.\n",
            "\n",
            " Loxe to petle \n",
            "\n",
            "\n",
            "step 100455: smooth_loss = 2.0258\n",
            "new text:  st.\n",
            "\n",
            "\n",
            "KENT.\n",
            "Wherswstor supjoll: you? I’st\n",
            "Two tikey prow fitsean him thou prose Agthaving losnaperg.\n",
            "\n",
            "\n",
            "step 101455: smooth_loss = 2.0265\n",
            "new text:  , hinsth love\n",
            "Gownan is doans thas: to wme heaved\n",
            "If\n",
            "lasie my seak, all an ould; will and agas make.\n",
            "\n",
            "\n",
            "step 102460: smooth_loss = 2.0239\n",
            "new text:   _Hverpieslrows._]\n",
            "Enge tham dangess you there O caviner sice and how net at,; bess, sarmmor\n",
            "And are\n",
            "\n",
            "\n",
            "step 103464: smooth_loss = 2.0366\n",
            "new text:   ays\n",
            "Pomes awace to uter the Rengeled mades dowan a and straga in me kack crow your scale to my not \n",
            "\n",
            "\n",
            "step 104465: smooth_loss = 2.0794\n",
            "new text:  \n",
            "    Fnat us of mat\n",
            "'nat vaodsty squit blace ub stky\n",
            "  talf and kn the that nes erbe blap: had bay c\n",
            "\n",
            "\n",
            "step 105470: smooth_loss = 2.0253\n",
            "new text:  CE I tth gome\n",
            "                     BRRTHOS.\n",
            "  ROSHEN. Leatt that hers io his greephess,\n",
            "\n",
            "   where me\n",
            "\n",
            "\n",
            "step 106475: smooth_loss = 1.9480\n",
            "new text:  ore]\n",
            "          womineon? I bett?\n",
            "                    Anoun? ORIN, If, inr cottalne thatholy? thy a w\n",
            "\n",
            "\n",
            "step 107478: smooth_loss = 1.9537\n",
            "new text:  r Leid.\n",
            "  KING. Thets\n",
            "    pair like. As love dirch oldmere.\n",
            "  BEROLI. I firire honsiokes. Ockice wil\n",
            "\n",
            "\n",
            "step 108487: smooth_loss = 1.9076\n",
            "new text:   bing wat suck.\n",
            "  RRINCESS ORI yoon do be as no the make muy onded they fascues as meaurs. We our el\n",
            "\n",
            "\n",
            "step 109496: smooth_loss = 1.8685\n",
            "new text:  tne'd ta that I in 'edoon, I loents, and thit unes,\n",
            "    Or a erake, and you ore.\n",
            "  HOLOF'DN. The Hla\n",
            "\n",
            "\n",
            "step 110500: smooth_loss = 2.0204\n",
            "new text:  .glith’ besh.\n",
            "\n",
            "UCUNCUTUT.\n",
            "Yettay no the to me lowing sil\n",
            "And us chep, me her Nor unend.\n",
            "\n",
            "The wasbel’\n",
            "\n",
            "\n",
            "step 111500: smooth_loss = 2.0465\n",
            "new text:   stras.\n",
            "\n",
            "MACBEL.\n",
            "Have of refuis smores.\n",
            "\n",
            "MANCOLO.\n",
            "Whays.\n",
            "\n",
            "OLEN TILB. Lut the soy to mer’s slert\n",
            "The \n",
            "\n",
            "\n",
            "step 112503: smooth_loss = 2.0354\n",
            "new text:  S, no, dorirure a Pirire,\n",
            " for of onke. Lake bufrirue,\n",
            "Lord,, backur, ble at and in countribovech;\n",
            "I\n",
            "\n",
            "\n",
            "step 113512: smooth_loss = 2.0329\n",
            "new text:  kn’n mear blotsin havand my manqurncing men!\n",
            "\n",
            "LECOLERARW\n",
            "MG.\n",
            "This have, whre my the pood pere; daysi\n",
            "\n",
            "\n",
            "step 114513: smooth_loss = 2.0243\n",
            "new text:  himg my lotting will to prugh ligply will it the be\n",
            "    Whosesised to do I our; you on shid; all\n",
            "van\n",
            "\n",
            "\n",
            "step 115520: smooth_loss = 1.9335\n",
            "new text:  a\n",
            "    Sure\n",
            "              PROVBANGAI.\n",
            "  SARVANCLE.\n",
            " ESath'gr'd hoy,\n",
            "    Rore their.\n",
            "  DHand'n.\n",
            " Preta\n",
            "\n",
            "\n",
            "step 116525: smooth_loss = 1.8677\n",
            "new text:  Ud hr. TRABBO. I me to and memy.\n",
            "  CLAUDIO L'W\n",
            "  CLAUDIO. Won,\n",
            "    But deablee? peald all as dinsing\n",
            "\n",
            "\n",
            "step 117532: smooth_loss = 1.8680\n",
            "new text:  tants, I upren,, to-thereforfers, sheser, arkent!\n",
            " LERIANTANE.\n",
            "\n",
            "   A bege for I have me cord, exey; \n",
            "\n",
            "\n",
            "step 118537: smooth_loss = 1.8656\n",
            "new text:  anowy Ro tthath's achetime, you, shall thim me comf.\n",
            "  Artess, at of the trimbroursce;         fourd\n",
            "\n",
            "\n",
            "step 119546: smooth_loss = 1.8487\n",
            "new text:  nt I my I hor netaelan.\n",
            "    Theremor,\n",
            "    Thenesenhe there\n",
            "    I you ances ornie.\n",
            "    Th Get lenting\n",
            "\n",
            "\n",
            "step 120549: smooth_loss = 2.0066\n",
            "new text:  thee diopast mast eped\n",
            "Afesnon’d my hereit’d;\n",
            "Be fievon and you my menmsy feis’diernifed.\n",
            "\n",
            "You witht\n",
            "\n",
            "\n",
            "step 121550: smooth_loss = 2.0293\n",
            "new text:  arfinaw fauratinO, the\n",
            "reuth\n",
            "Maniop.\n",
            "\n",
            "SALARIO.\n",
            "Fon is he it\n",
            "Bucht Lordond not, Fistrairstafele.\n",
            "\n",
            "A h\n",
            "\n",
            "\n",
            "step 122558: smooth_loss = 2.0323\n",
            "new text:   You ditend, os,, from cose ally yit poy,\n",
            "Seat serir’s sill me let thich crom of alld obrie consire\n",
            "\n",
            "\n",
            "\n",
            "step 123560: smooth_loss = 1.9898\n",
            "new text:  as conn.\n",
            "\n",
            " [_Sing therry sure the ca’th jusiwent, Pedfian fircce.\n",
            "\n",
            "PORTIA.\n",
            "Or fpingate hor puin this\n",
            "\n",
            "\n",
            "step 124563: smooth_loss = 2.0086\n",
            "new text:                       Gonge my nive\n",
            "      MASSOWILA PVALE. Vorsing thereriree you wher you.] Here. Pi\n",
            "\n",
            "\n",
            "step 125565: smooth_loss = 2.0075\n",
            "new text:   werve, ye prive\n",
            "       bell\n",
            "   'ny\n",
            "    Wive crow my hich with ill a-t asing\n",
            "   \n",
            "  is sir dear JiCgE\n",
            "\n",
            "\n",
            "step 126572: smooth_loss = 1.9469\n",
            "new text:  3if hiat\n",
            "  Inth and defoud in nive if dusce, and and nath froke life lookel, Isca.\n",
            " BAd tholl,\n",
            "sagou\n",
            "\n",
            "\n",
            "step 127581: smooth_loss = 1.8905\n",
            "new text:     Arour to afreltray.\n",
            "  CAGE.\n",
            "  SHe.  [ELENDH lowl go, Marsink,\n",
            "  MRR FORW. Wis love with of theres\n",
            "\n",
            "\n",
            "step 128581: smooth_loss = 1.8622\n",
            "new text:       Mak, luw of. Fere? I'll one. Me to Pome in here wake oRS. SCENECK PAGE. Sund\n",
            "    Shough bemI\n",
            " R\n",
            "\n",
            "\n",
            "step 129583: smooth_loss = 1.8923\n",
            "new text:  shite that ints the din this penafheroun in citt trupiter Ort, and the pa mistesly paok oth the titt\n",
            "\n",
            "\n",
            "step 130591: smooth_loss = 2.0275\n",
            "new text:  holjentol make bures sheys wellen the levengule give, rread rvess; is usw soom cairss shore, I live \n",
            "\n",
            "\n",
            "step 131595: smooth_loss = 2.0603\n",
            "new text:  ly them ont we tatht sung wit herer I that sough so scour the tount you mast lold though me and down\n",
            "\n",
            "\n",
            "step 132600: smooth_loss = 2.0239\n",
            "new text:  t, I tooy thy lansien ore not eent we ho, me up eody.\n",
            "\n",
            "TITSAA\n",
            "I.\n",
            "Hole the le to have footiun, I prey\n",
            "\n",
            "\n",
            "step 133606: smooth_loss = 1.9970\n",
            "new text:  l! saked.\n",
            "                  me Then anneres\n",
            "slow;\n",
            "\n",
            "DOMPus, fees, phalks in goerders.\n",
            "\n",
            " Tave ke heme \n",
            "\n",
            "\n",
            "step 134611: smooth_loss = 1.9475\n",
            "new text:  ut e tree at syof withreed a mascne or nee I wintrens in omat it trek maClzane amink: in my sade’ yh\n",
            "\n",
            "\n",
            "step 135612: smooth_loss = 1.8473\n",
            "new text:  aly me, a to makeggs be and bince     for shald thy\n",
            "    what busicu. I       wER jver, mut ter rothe\n",
            "\n",
            "\n",
            "step 136614: smooth_loss = 1.7877\n",
            "new text:  dot, therely, it ofl wris ter eware to dore your lide. His hip\n",
            "      towen till low sas some, alller\n",
            "\n",
            "\n",
            "step 137622: smooth_loss = 1.7618\n",
            "new text:  e noth this Jigh your, of Pome’d\n",
            "\n",
            "    EThefon.\n",
            "\n",
            "\n",
            " roth fave Douth.\n",
            "\n",
            "\n",
            "\n",
            "      Man ee for Jough o’;\n",
            "\n",
            "  \n",
            "\n",
            "\n",
            "step 138625: smooth_loss = 1.7096\n",
            "new text:  d net, chondt the, flllve your you had daply you he land to have.’\n",
            "      CLAUDIO.\n",
            "                  \n",
            "\n",
            "\n",
            "step 139629: smooth_loss = 1.7739\n",
            "new text:  atenTOF. Is madd whick berome, ittere hath aree hmobaly The boustaif, thich: cella atmeattesh hillai\n",
            "\n",
            "\n",
            "step 140631: smooth_loss = 1.9850\n",
            "new text:  gou him say,\n",
            "Lwtade bless\n",
            " beglambaning sabds and in hass\n",
            "I iitublelTsians gear\n",
            "Agaurs,\n",
            "I allingives\n",
            "\n",
            "\n",
            "step 141634: smooth_loss = 2.0428\n",
            "new text:  y shalm and she dood am his as youly. I pronk;—Hasthiet is seally; samn of Cank mosmk tart that thei\n",
            "\n",
            "\n",
            "step 142639: smooth_loss = 1.9928\n",
            "new text:  tus, lisch!\n",
            "\n",
            "\n",
            "What dipy your bid, fainted thy lightato for to feich merier llard?\n",
            "\n",
            "OTHELLO.\n",
            "I willed\n",
            "\n",
            "\n",
            "step 143645: smooth_loss = 1.9595\n",
            "new text:  ench or mult.\n",
            "\n",
            "sill seel conce buref obpeck._]\n",
            "\n",
            "I salsong!\n",
            "\n",
            " [_Aksilfurm.\n",
            " ’Tobe noul wise mayniand \n",
            "\n",
            "\n",
            "step 144647: smooth_loss = 1.9284\n",
            "new text:  xaw the limcrer’s that trion,\n",
            " hat love,\n",
            "range no’t rrict.— you config gasse triaw\n",
            "  [_Sithas.—\n",
            "  [_\n",
            "\n",
            "\n",
            "step 145647: smooth_loss = 1.8989\n",
            "new text:  ouffaw, I’s sre kndt sores with her, ampard are thise,\n",
            "Chost whase dean shy and is tats, isserp do l\n",
            "\n",
            "\n",
            "step 146655: smooth_loss = 2.0225\n",
            "new text:  giver;\n",
            "Anter hespet!\n",
            "\n",
            "PERICO.\n",
            "Wellon pein to wit the priights lith’s revians of allion yond it worgh\n",
            "\n",
            "\n",
            "step 147662: smooth_loss = 2.0029\n",
            "new text:  WAant\n",
            "Tarus b.\n",
            "\n",
            "SIMOWICLES. So, samed\n",
            "That you safe tas, halse you, note tour fill rist have your a \n",
            "\n",
            "\n",
            "step 148668: smooth_loss = 2.0412\n",
            "new text:  ietork.\n",
            "\n",
            "BASD thach\n",
            "me: acompy of porst pray thou’d no here I ware a. paikemadingpvast bmank them  i\n",
            "\n",
            "\n",
            "step 149671: smooth_loss = 2.0027\n",
            "new text:  y to\n",
            "I blaldevpape’nad.\n",
            "\n",
            "PERICLES.\n",
            "Por thesdoincstel?\n",
            "\n",
            "MARICY.\n",
            "FrimI dood this stake think.\n",
            "\n",
            "MERICLE\n",
            "\n",
            "\n",
            "step 150679: smooth_loss = 2.0919\n",
            "new text:   retort\n",
            "    An, leffinget con at of llover tompen, heand falon it.\n",
            "     lal worge tomen thoLB thete,\n",
            "\n",
            "\n",
            "step 151686: smooth_loss = 2.0228\n",
            "new text:  ALI theesintshings is thon is homely bost I sI daisgs thee thon is me notsick thas it thy cieth chol\n",
            "\n",
            "\n",
            "step 152688: smooth_loss = 1.9580\n",
            "new text:  the Diving angengiousker blood fhnabants hath hit\n",
            "  You noble leakion at that hough thatt, resal,\n",
            " h\n",
            "\n",
            "\n",
            "step 153690: smooth_loss = 1.9283\n",
            "new text:  and his their\n",
            "    Shat?\n",
            "    My shal these\n",
            "    Besver I's ablt,\n",
            "    Man;\n",
            "    Nore, fal and it for tic\n",
            "\n",
            "\n",
            "step 154698: smooth_loss = 1.8957\n",
            "new text:   leno? Risin?\n",
            "  BARLE. Oasiobing bould bept iw\n",
            "    These,\n",
            "    To thou the back?\n",
            "  KINK.. mow' allen \n",
            "\n",
            "\n",
            "step 155700: smooth_loss = 1.8528\n",
            "new text:  ong the Kitrent\n",
            "    Where o, to marth, hirgt wabun tell pe thy deriling ist;\n",
            "    Thy gfol the warder\n",
            "\n",
            "\n",
            "step 156708: smooth_loss = 1.8999\n",
            "new text:  ving,\n",
            " \n",
            "  I a kret.\n",
            "  BESTENE TIg     By lrany, livorsest,\n",
            "    Frimase!\n",
            "    Drin then or in armert n\n",
            "\n",
            "\n",
            "step 157709: smooth_loss = 1.8780\n",
            "new text:  a tow. Fereren ore the came lese some concences that uthirn is if wanl Minsortreentin, concest Deell\n",
            "\n",
            "\n",
            "step 158711: smooth_loss = 1.8714\n",
            "new text:  \n",
            "        Whee well. Neart wheres fearry smur;\n",
            "      me the can my hathe'd.\n",
            "\n",
            "            lenten mathe\n",
            "\n",
            "\n",
            "step 159718: smooth_loss = 1.8476\n",
            "new text:   sombongsands MLIT Have a setless.\n",
            "  fnay that of Pxour you, you yusings busingsinghoad, thines]\n",
            "   \n",
            "\n",
            "\n",
            "step 160720: smooth_loss = 1.8633\n",
            "new text:  ncle.\n",
            "    and thenald we theallen'd well the Bordle.\n",
            "    Is, \n",
            "  CAYES ELIZABY. Siek's like Enrect, w\n",
            "\n",
            "\n",
            "step 161724: smooth_loss = 1.8387\n",
            "new text:  Ny he say comon Rears,\n",
            "    Tho royf, my ereshine doy's in bn greathurdond' you waes crace hes yours \n",
            "\n",
            "\n",
            "step 162733: smooth_loss = 1.8451\n",
            "new text:  nvhlu sold a mice Unul noveroup-lood minnt, my stay os for her.\n",
            "    And thunk the falloordo-uphs.\n",
            "  \n",
            "\n",
            "\n",
            "step 163738: smooth_loss = 1.9852\n",
            "new text:   cittan, Colilce,\n",
            "Welm,\n",
            " ABd hiid Cive stimeensn,, Lirturat trentartw;\n",
            "And tattet-testenten,\n",
            "Ald\n",
            "I t\n",
            "\n",
            "\n",
            "step 164743: smooth_loss = 2.0505\n",
            "new text:  e\n",
            "Youtn?\n",
            "That Buse!\n",
            "A my him the hous, good.\n",
            "Wheresye coull mompus, munq! hath, liealy!\n",
            "By, at.\n",
            "What\n",
            "\n",
            "\n",
            "step 165749: smooth_loss = 2.0058\n",
            "new text:  Iilan, finding;\n",
            "Nus’ fondlettys, bed and cale-likigghing sounce. SOMIO.\n",
            "Nook the grosel!shlinian, Is\n",
            "\n",
            "\n",
            "step 166750: smooth_loss = 2.0200\n",
            "new text:  wear do Rord-mipuidat fare Pombon was or aherermand.\n",
            "\n",
            "LRERELE.\n",
            "Alide terment,\n",
            "Fath all and hond, to \n",
            "\n",
            "\n",
            "step 167759: smooth_loss = 1.9666\n",
            "new text:  \n",
            "\n",
            "ThmATCEECE.\n",
            "Gore batere stirnort!\n",
            "That head came\n",
            "That arrung dent.\n",
            "\n",
            "JULIETET.\n",
            "Thou than dond spcna\n",
            "\n",
            "\n",
            "step 168766: smooth_loss = 2.0026\n",
            "new text:  lont thee-streuth, mare; the stist. For you werge me deaves.\n",
            "For that dilloun thane,, tinq kasky. Ro\n",
            "\n",
            "\n",
            "step 169768: smooth_loss = 2.0721\n",
            "new text:  Mpiite to que.\n",
            "My some Luate, and you’ct vors;\n",
            "to Sthis quiquiscefious lives\n",
            "O sumiivet.\n",
            "\n",
            "\n",
            "GLANTOM M\n",
            "\n",
            "\n",
            "step 170770: smooth_loss = 2.0220\n",
            "new text:  gung unnet?\n",
            "\n",
            "Grive you bidreal; Guous thouG, Goorerielio, o. Go wirnious in of weed Turvaw shoughtes\n",
            "\n",
            "\n",
            "step 171772: smooth_loss = 2.0093\n",
            "new text:  nie fare?\n",
            "\n",
            "BIONDELLO.\n",
            "Whoth and Sirtt awchares;\n",
            " lancebn fif liener at achaintise! amoaye, a praisin\n",
            "\n",
            "\n",
            "step 172776: smooth_loss = 1.9602\n",
            "new text:  ,ERVUCHIOA.\n",
            "Gedet o congide live them me sgove I that, hed appale,\n",
            "And wheir;\n",
            "Good.\n",
            "\n",
            "BAPONIO.\n",
            "I fute\n",
            "\n",
            "\n",
            "step 173782: smooth_loss = 1.9121\n",
            "new text:  dis.\n",
            "Hosben With tpe wither But Grinke towk. Hen eventio your dewfid fery my hersulfker te lemsh,\n",
            "Lu\n",
            "\n",
            "\n",
            "step 174786: smooth_loss = 2.0366\n",
            "new text:  icheril hipper gidser’s weefondceline why witping what uppend, with\n",
            "What is wheredirich pirzs, and m\n",
            "\n",
            "\n",
            "step 175792: smooth_loss = 2.0130\n",
            "new text:  Upun? \n",
            "GEBSSIO.\n",
            "Artiher she hen look, holloundny host a consh shoribll of of ilis.\n",
            "\n",
            "ALONSO.\n",
            "Ut mord?\n",
            "\n",
            "\n",
            "step 176793: smooth_loss = 2.0108\n",
            "new text:  on theungert’p orit, them ey peatchecty for sto,\n",
            "And, hole, heareres, watce sued thy gent hallecy th\n",
            "\n",
            "\n",
            "step 177797: smooth_loss = 2.0412\n",
            "new text:  kereten with our hinker a! Sour tolo fare, this of apvees be wise, a follofe: amote\n",
            "Wiloly, of rOeso\n",
            "\n",
            "\n",
            "step 178806: smooth_loss = 2.0054\n",
            "new text:  hap, one attance\n",
            "    A eve Mut to ant me, thy am wim noth dordiss: my dook ter that that, lesty, wil\n",
            "\n",
            "\n",
            "step 179806: smooth_loss = 1.9445\n",
            "new text:   entunns untulast toury pramptesiss hy that that to—Soinonm\n",
            "    Enthoogs\n",
            "    Lient ab that heak clom\n",
            "\n",
            "\n",
            "step 180813: smooth_loss = 1.8871\n",
            "new text:  a buth\n",
            "                             Hast the gose's now forreth! Had bray, shall a bays shee a groug\n",
            "\n",
            "\n",
            "step 181813: smooth_loss = 1.8449\n",
            "new text:  'st grac'seels\n",
            "    The spint ie loris'?\n",
            "  To do, blivy save ort follsia?\n",
            "  TIMON. Here's'sibpespiipa\n",
            "\n",
            "\n",
            "step 182818: smooth_loss = 1.8659\n",
            "new text:   mesert take wers, Ind the crost mard. NECONDES. Entreed rue coll hon my fain thaimed, fupt terser w\n",
            "\n",
            "\n",
            "step 183818: smooth_loss = 1.8949\n",
            "new text:  t daind to thou'tsy\n",
            "  NATNANTUSl' prochepy nived but kut of thee,\n",
            "    Lrust youss fath.\n",
            "  TITUNUNUS \n",
            "\n",
            "\n",
            "step 184822: smooth_loss = 1.8842\n",
            "new text:  RATUTTI. Thooter wouser stay hl, is cambundare yours is with hinghorata, ongot no hounds.\n",
            "  [Oy To t\n",
            "\n",
            "\n",
            "step 185822: smooth_loss = 1.8457\n",
            "new text:  of Mozem\n",
            "    Cuey, Ray make sheed I taks\n",
            "    Af gemer cae shou hander sears nef it frepss wIfress me\n",
            "\n",
            "\n",
            "step 186825: smooth_loss = 1.8707\n",
            "new text:  y\n",
            "    And what sbe why sips.\n",
            "  AARON. Wht buse agaundrs\n",
            "    Gostrave hays me but to shencent just An\n",
            "\n",
            "\n",
            "step 187828: smooth_loss = 1.8391\n",
            "new text:  ose imer disingees temfong a muse lustus Roprorderess,\n",
            "    To shy bandurt, misery sreaker bondathes \n",
            "\n",
            "\n",
            "step 188829: smooth_loss = 1.9890\n",
            "new text:  I houtuldo Dirgoy.\n",
            "\n",
            "PANDARURUUS.\n",
            "\n",
            "Cooderwerensiece, when, tlemer, oroseles, mae! Hild!\n",
            "\n",
            "CRESSA.\n",
            "\n",
            "PRE\n",
            "\n",
            "\n",
            "step 189838: smooth_loss = 2.0523\n",
            "new text:  usses, Af neare swill hwans e ing opce,\n",
            "Me, PIARPIL’s bece?\n",
            "TRNaSt her.\n",
            "Then? poilh faile etpecf.\n",
            "\n",
            "T\n",
            "\n",
            "\n",
            "step 190844: smooth_loss = 2.0274\n",
            "new text:  Win, suchend.\n",
            "Hast ane dove one him disteld yome?\n",
            "Shy, my fees\n",
            "stais.\n",
            "\n",
            "NERTAR.\n",
            "No.\n",
            "\n",
            "PENEMI.\n",
            "\n",
            "CANE We\n",
            "\n",
            "\n",
            "step 191845: smooth_loss = 2.0214\n",
            "new text:  wIUS.\n",
            "\n",
            "CRTILTIS.\n",
            "Gook, Prly but comc!\n",
            "Host ey to not bace they.\n",
            "The dect’d.\n",
            "SCa!\n",
            "Andonch.\n",
            "\n",
            "PATROT.\n",
            "T\n",
            "\n",
            "\n",
            "step 192847: smooth_loss = 1.9869\n",
            "new text:  n.\n",
            "\n",
            "THORSEOTAD.\n",
            "Whut eruly op theath ijrore,\n",
            "\n",
            "\n",
            "THOILORS.\n",
            "Os’s’dceet, hime inst.\n",
            "\n",
            "ATAXEMOAS.\n",
            "Theide.\n",
            "\n",
            "\n",
            "\n",
            "step 193853: smooth_loss = 1.9758\n",
            "new text:  lleme!\n",
            "Heayny shome dothery ourede.\n",
            "Fear is, you.\n",
            "Lndich didousmo! beave to theur hole, man, reck!\n",
            "A\n",
            "\n",
            "\n",
            "step 194859: smooth_loss = 2.0396\n",
            "new text:  hara,\n",
            "\n",
            "SIR ENDAREV.\n",
            "Vally lay conccencaus or he o\n",
            "with sulf, a doder shour onetina,\n",
            "Nif this tho kec\n",
            "\n",
            "\n",
            "step 195865: smooth_loss = 1.9951\n",
            "new text:  Ro’s them of make.\n",
            "\n",
            "SOR that your so kecuewadys.\n",
            "\n",
            "MARIOW.\n",
            "Grimer frake virbmon you?\n",
            "\n",
            "CLOWRA.\n",
            "And of \n",
            "\n",
            "\n",
            "step 196871: smooth_loss = 1.9608\n",
            "new text:  s.\n",
            "SEREST.\n",
            "Senther, nog love.\n",
            "\n",
            "SIR ANDRII.\n",
            "Hery.\n",
            "Send, And as inge, but couptaned one.\n",
            "\n",
            "SIR ANDRA.\n",
            "A\n",
            "\n",
            "\n",
            "step 197879: smooth_loss = 1.9489\n",
            "new text:  res This the pannatton. The feluw This them?\n",
            "\n",
            "SIR, wel no sirn.\n",
            "Winderinghoriest’s\n",
            "pray Sisss. To’s \n",
            "\n",
            "\n",
            "step 198884: smooth_loss = 1.9496\n",
            "new text:  \n",
            "Thou but mastom’ hall go pullu, mone reaves countel’bp’th’s she, Bft whose min’snex resurl now thre\n",
            "\n",
            "\n",
            "step 199889: smooth_loss = 1.9161\n",
            "new text:   what there your himh seean tell homed hir'd thin,\n",
            "    that shen; shall onihard that weak our       \n",
            "\n",
            "\n",
            "step 200891: smooth_loss = 1.8481\n",
            "new text:  exge, stind perangen one to sne, nogss she prayed\n",
            "    Rount oper my fe.\n",
            "  CUIN. That and un,\n",
            "so less\n",
            "\n",
            "\n",
            "step 201894: smooth_loss = 1.8180\n",
            "new text:  p galatsy!\n",
            "  PIOTEUS. Powet\n",
            "    Deepanneds\n",
            "    And corny one pupperten aud beposeupe toreet' is pray\n",
            "\n",
            "\n",
            "step 202897: smooth_loss = 1.8244\n",
            "new text:              Which with in you was agge.\n",
            "  Exit Sillice'ct?\n",
            "  DAKEUN..  VRpren ben.\n",
            "    The losepf, t\n",
            "\n",
            "\n",
            "step 203901: smooth_loss = 2.0315\n",
            "new text:  s?\n",
            "\n",
            "MARTIAEG.\n",
            "The bigiar bniking In Bore for and ritne deis, bost,\n",
            "The deede?\n",
            "\n",
            "Tunce be I in weer? Y\n",
            "\n",
            "\n",
            "step 204904: smooth_loss = 2.0486\n",
            "new text:   much wall midat.\n",
            "\n",
            "PALAMOMOODIN.\n",
            "That leash more a destas a though hound, In reaches\n",
            "And mouide,\n",
            "Afl\n",
            "\n",
            "\n",
            "step 205909: smooth_loss = 2.0531\n",
            "new text:  —3 hy a as hike have am ne goe, shang now a you 2ach har gizan\n",
            "\n",
            "3 let he the home that a mainterce\n",
            "A\n",
            "\n",
            "\n",
            "step 206911: smooth_loss = 2.0094\n",
            "new text:  ele here.\n",
            "\n",
            " Tren, thee hetene; In wooliessse, afters I Cone eu'll you on me,\n",
            "Wet, 'eeor.\n",
            "\n",
            "THAS.\n",
            "Slen\n",
            "\n",
            "\n",
            "step 207915: smooth_loss = 2.0655\n",
            "new text:  e cut Broves have pige\n",
            "This\n",
            "Alad's\n",
            "Hy forthoure, they sune putte wolles theslibauce ausoos,\n",
            "Nap goos\n",
            "\n",
            "\n",
            "step 208924: smooth_loss = 2.0707\n",
            "new text:  an he matoughing Chang faight of the gave hich this his he langen yeaden fase\n",
            "Thy forh hsing, hent's\n",
            "\n",
            "\n",
            "step 209925: smooth_loss = 2.0733\n",
            "new text:  ory,\n",
            "Loselrer’d littel we. rar’dier.\n",
            "\n",
            "PAMILLO.\n",
            "Gohd\n",
            "As with deavend gray tomelfay, in as cheak,. Kid\n",
            "\n",
            "\n",
            "step 210926: smooth_loss = 2.0360\n",
            "new text:   the qeele.\n",
            "\n",
            "(Enteese but there gourt. For, with Jurelne tie vake, though sultoursent.\n",
            "I lith alee s\n",
            "\n",
            "\n",
            "step 211932: smooth_loss = 2.0450\n",
            "new text:  CAULILA.\n",
            "And croening! and b’ a\n",
            "\n",
            " A hoot ma so the gisp, ched thoughs ther, bno? A me\n",
            "receats hight!\n",
            "\n",
            "\n",
            "step 212941: smooth_loss = 2.0071\n",
            "new text:  d, Pedly him brime som. I. Leedvesd one, bad featiald;\n",
            "Why steede brated, and stouncts fer wice sutp\n",
            "\n",
            "\n",
            "step 213946: smooth_loss = 1.9742\n",
            "new text:  his fol namen, Alg the for was hingh,\n",
            "No, givf spee, was is feavan,\n",
            "Fath ’tom, ouy his antne so and \n",
            "\n",
            "\n",
            "step 214950: smooth_loss = 2.0008\n",
            "new text:  d upnd,\n",
            "The blure,\n",
            "Sheat Lady the from twastiituencee hrowently dake plestunitand her a conthurpind,\n",
            "\n",
            "\n",
            "step 215957: smooth_loss = 2.0951\n",
            "new text:  de' ande,\n",
            " fad bee they,\n",
            "'rimer shan sore shead and and bresures'd, is for in lindienced is warquese\n",
            "\n",
            "\n",
            "step 216957: smooth_loss = 2.0645\n",
            "new text:  h m's leed to why epe, thou wim comforded:\n",
            "Thee wayot outhindyitalingsice:\n",
            " The pestiicys kin welow'\n",
            "\n",
            "\n",
            "step 217961: smooth_loss = 2.0486\n",
            "new text:  n my love foll,\n",
            "My stoubhrouthend:\n",
            "layer shaiques;\n",
            "Mem this beat'd mike; firfian in bioks,\n",
            "'Murguigo\n",
            "\n",
            "\n",
            "step 218961: smooth_loss = 2.0424\n",
            "new text:  rie evir.\n",
            " 'Ligily lliawe, Lach, so sow?\n",
            "Lotherses it criee her dose 'lie she iting iats.\n",
            "\n",
            "Where.\n",
            "  \n",
            "\n",
            "\n",
            "step 219969: smooth_loss = 2.0266\n",
            "new text:  ch preas,\n",
            "Tpruld lellick foecliang goth one of ead,\n",
            "Mat a fare,   lord, ’nould be lreen ece, agallab\n",
            "\n",
            "\n",
            "step 220976: smooth_loss = 1.9883\n",
            "new text:  the blageul shear,\n",
            "Where-  Loake eraked wher;\n",
            "      82d\n",
            "Sonse too reiping aloforil anoce prough sill\n",
            "\n",
            "\n",
            "step 221984: smooth_loss = 2.1761\n",
            "new text:  is\n",
            "  Yet- rops any in mo hr pimele. *rovect wonecy pry\n",
            "  Younters\n",
            "A Pedven,\n",
            "And with dexming comy of\n",
            "epoch 1 started --------------------------\n",
            "\n",
            "\n",
            "step 222991: smooth_loss = 2.1199\n",
            "new text:  your my stailils more,\n",
            "Thy varst mores,\n",
            "  She,\n",
            "What thy leive:\n",
            "       \n",
            "Ansorase strice, awrani’s’,,\n",
            "\n",
            "\n",
            "\n",
            "step 223991: smooth_loss = 1.9652\n",
            "new text:   do their sowesbil’s sairy,\n",
            "Nos that brtrowed,\n",
            "Then strokrembighions?\n",
            "Their tearts spull sala on the\n",
            "\n",
            "\n",
            "step 224996: smooth_loss = 1.8909\n",
            "new text:   thing,\n",
            "But le thee udy,\n",
            "And that down the light the seterer to that thou mlave,\n",
            "And loum soorg loio\n",
            "\n",
            "\n",
            "step 226001: smooth_loss = 1.8717\n",
            "new text:  y be make me aypselt beweet wmur souly embeatal nee in need,\n",
            "Of not dead’d of play our eibuting?\n",
            "  W\n",
            "\n",
            "\n",
            "step 227004: smooth_loss = 1.9829\n",
            "new text:  ok to spen it quonl hrmexs wiblmy; no the are fall or wext, I mariquans thy qoonhy, Mostlance; my be\n",
            "\n",
            "\n",
            "step 228013: smooth_loss = 1.9663\n",
            "new text:  ars that soremfown surert ar a nedsiar feremed and afttes.\n",
            " HELEN.\n",
            "Hill brard, saok riquell suff res\n",
            "\n",
            "\n",
            "step 229013: smooth_loss = 1.9089\n",
            "new text:  SECTNENA.\n",
            "Syowuse ifarase use?\n",
            "\n",
            "\n",
            "SCENENAMEMST.\n",
            "Sherays that\n",
            "O chimf, and and and I thise’ cithine,\n",
            "N\n",
            "\n",
            "\n",
            "step 230015: smooth_loss = 1.9242\n",
            "new text:   rrooght hem; mane esicn, anquare my etiong,.\n",
            "\n",
            "MECEW.\n",
            "I.\n",
            "\n",
            "BERTRAMS.\n",
            "My hougls\n",
            "rorely comment no gith\n",
            "\n",
            "\n",
            "step 231017: smooth_loss = 1.8978\n",
            "new text:  sans,\n",
            "These to\n",
            "is yours nated ut? God am is see which comesero whis premged, withul guilions shall y\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-367-afeae37e3f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdparams_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflat_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mparams_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdparams_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mWxh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-364-8ed4184a6349>\u001b[0m in \u001b[0;36mreshape_params\u001b[0;34m(params_flat, params_sample)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_flat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_sample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \"\"\"\n\u001b[1;32m   2961\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\n\u001b[0;32m-> 2962\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}