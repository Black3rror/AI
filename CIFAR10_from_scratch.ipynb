{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10 from scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMEDcI4QerY7ekvK07dV/VE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Black3rror/AI/blob/master/CIFAR10_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMJOXM-S4mcC",
        "colab_type": "text"
      },
      "source": [
        "# Goal\n",
        "\n",
        "The goal is implimenting a model to solve MNIST from scratch (just numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNenJD0f5CG9",
        "colab_type": "text"
      },
      "source": [
        "# Importing stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IFzQqHf4QqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow   # to compare with our classes\n",
        "from tensorflow.keras.datasets.cifar10 import load_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khGLBsFU51N_",
        "colab_type": "text"
      },
      "source": [
        "# New classes and functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBgR5pDM5_av",
        "colab_type": "text"
      },
      "source": [
        "## Initializations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NzSmmN56GIv",
        "colab_type": "text"
      },
      "source": [
        "### Xavier initialization (He)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG4RomLn6OYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "@brief Xavier or He initializer\n",
        "@param w_dims: current layers param dimention (shape), like (3,) or (3,1) for dense or (2,2) for conv\n",
        "@param l_dims: current layers dimention (shape), like (3,) or (3,1) for dense or (2,2) for conv\n",
        "@return param: created parameter of shape l_dims\n",
        "\"\"\"\n",
        "def xavier(p_dims, l_1_dims):\n",
        "  param = np.random.standard_normal(p_dims) / np.sqrt(np.prod(l_1_dims)) * 0.01\n",
        "  param = param.reshape(p_dims)\n",
        "\n",
        "  return param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGQgYKeL9GPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "63cbc0e1-7366-4f1e-da40-29488f8c1519"
      },
      "source": [
        "np.random.seed(1)\n",
        "print(xavier((9, 1), (4, 1)))\n",
        "np.random.seed(1)\n",
        "print(\"\\n\", xavier((9,), (16,)))\n",
        "\n",
        "np.random.seed(1)\n",
        "print(\"\\n\\n\", xavier((3, 3), (2, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00812173]\n",
            " [-0.00305878]\n",
            " [-0.00264086]\n",
            " [-0.00536484]\n",
            " [ 0.00432704]\n",
            " [-0.01150769]\n",
            " [ 0.00872406]\n",
            " [-0.00380603]\n",
            " [ 0.0015952 ]]\n",
            "\n",
            " [ 0.00406086 -0.00152939 -0.00132043 -0.00268242  0.00216352 -0.00575385\n",
            "  0.00436203 -0.00190302  0.0007976 ]\n",
            "\n",
            "\n",
            " [[ 0.00812173 -0.00305878 -0.00264086]\n",
            " [-0.00536484  0.00432704 -0.01150769]\n",
            " [ 0.00872406 -0.00380603  0.0015952 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0mqYwZvUs_E",
        "colab_type": "text"
      },
      "source": [
        "### Zeros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C0al0zEUvuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zeros(l_dims):\n",
        "  param = np.zeros(l_dims)\n",
        "  return param"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO0ipYXpGFzl",
        "colab_type": "text"
      },
      "source": [
        "## Loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQlBiUeiGtaT",
        "colab_type": "text"
      },
      "source": [
        "### Categorical crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvUkwe4hGy_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "@return batch-result: averaged loss over batch, compressed to one number\n",
        "@return gradient: averaged dL/dyhat over batch\n",
        "      shapes\n",
        "------------------\n",
        "y:            (m, units) or (units)\n",
        "yhat:         (m, units) or (units)\n",
        "batch-result: float\n",
        "gradient:     (m, units)\n",
        "\n",
        "logp:            (m, units)\n",
        "example_results: (m, 1)\n",
        "\"\"\"\n",
        "def categorical_crossentropy(y, yhat, epsilon = 1e-7):\n",
        "  assert yhat.shape == y.shape\n",
        "  assert len(y.shape) <= 2\n",
        "\n",
        "  # if inputs are in shape of (n,) (one example) convert them to (1, n) (batch)\n",
        "  if len(y.shape) == 1:\n",
        "    yhat = yhat.reshape((1, -1))\n",
        "    y = y.reshape((1, -1))\n",
        "  \n",
        "  logp = y * np.log(yhat+epsilon)\n",
        "  example_results = np.sum(-logp, axis = 1, keepdims=True)\n",
        "  batch_result = np.average(example_results)\n",
        "\n",
        "  gradient = -1 * (y / (yhat+epsilon) - (1-y) / (1-yhat+epsilon))    # dLn(x)/dx = 1/x\n",
        "\n",
        "  return batch_result, gradient"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swfKo8GtQhld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3b32bef3-d145-4cb0-bf5a-e0f41e6ea542"
      },
      "source": [
        "a = np.array([0,   0,   1])\n",
        "b = np.array([0.7, 0.1, 0.2])\n",
        "c = np.array([[0,   0,   1],   [1,   0,   0],   [0,   0,   1],   [0,   1,   0]])\n",
        "d = np.array([[0.7, 0.2, 0.1], [0.8, 0.2, 0.0], [0.5, 0.2, 0.3], [0.1, 0.7, 0.2]])\n",
        "\n",
        "print(\"my loss: \", categorical_crossentropy(a, b)[0])\n",
        "\n",
        "loss = tensorflow.keras.losses.categorical_crossentropy(a, b)\n",
        "print(\"tf loss: \", loss.numpy())\n",
        "\n",
        "print(\"my loss: \", categorical_crossentropy(c, d)[0])\n",
        "\n",
        "loss = tensorflow.keras.losses.categorical_crossentropy(c, d)\n",
        "print(\"tf loss: \", np.average(loss.numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my loss:  1.6094374124342252\n",
            "tf loss:  1.6094379124341003\n",
            "my loss:  1.0215936978457554\n",
            "tf loss:  1.021594098143231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClcMW2IRcQ_i",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS4-5_vJcTvn",
        "colab_type": "text"
      },
      "source": [
        "### Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrlId6ncc43n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Adam():\n",
        "  def __init__(self, learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, step = 1, epsilon = 1e-7):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.beta1 = beta_1\n",
        "    self.beta2 = beta_2\n",
        "    self.step = step\n",
        "    self.epsilon = epsilon\n",
        "    self.first_moment = None\n",
        "    self.second_moment = None\n",
        "  \n",
        "  \"\"\"\n",
        "        shapes\n",
        "  ------------------\n",
        "  vars:         (vars, 1)\n",
        "  grads:        (vars, 1)\n",
        "  vars_changes: (vars, 1)\n",
        "  \"\"\"\n",
        "  def __call__(self, vars, grads, step = None):\n",
        "    assert len(vars.shape) == 2\n",
        "    assert vars.shape[1] == 1\n",
        "    assert vars.shape == grads.shape\n",
        "    if isinstance(step, int):\n",
        "      self.step = step\n",
        "    \n",
        "    vars_changes = self.compute_changes(grads)\n",
        "    return vars + vars_changes\n",
        "  \n",
        "  \"\"\"\n",
        "  @brief computes the amount changes needed for optimize variables\n",
        "        shapes\n",
        "  ------------------\n",
        "  grads:        (vars, 1)\n",
        "  changes: (vars, 1)\n",
        "  \"\"\"\n",
        "  def compute_changes(self, grads, step = None):\n",
        "    if self.first_moment is None:\n",
        "      self.first_moment = np.zeros_like(grads)\n",
        "      self.second_moment = np.zeros_like(grads)\n",
        "\n",
        "    assert self.first_moment.shape == grads.shape\n",
        "    assert self.second_moment.shape == grads.shape\n",
        "    \n",
        "    if isinstance(step, int):\n",
        "      self.step = step\n",
        "\n",
        "    self.first_moment = self.beta1 * self.first_moment + (1 - self.beta1) * grads\n",
        "    self.second_moment = self.beta2 * self.second_moment + (1 - self.beta2) * grads * grads\n",
        "    first_unbiased = self.first_moment / (1 - self.beta1 ** self.step)\n",
        "    second_unbiased = self.second_moment / (1 - self.beta2 ** self.step)\n",
        "\n",
        "    changes = - self.learning_rate * first_unbiased / (np.sqrt(second_unbiased + self.epsilon))\n",
        "    return changes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofWEgR_jsjsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "4b530088-0dce-47c7-816c-980d577268a6"
      },
      "source": [
        "a = np.array([1.1, 2.2, 3.3]).reshape(-1, 1)\n",
        "b = np.array([0.5, 5, -0.3]).reshape(-1, 1)\n",
        "opt = Adam()\n",
        "print(opt(a, b))\n",
        "\n",
        "# optimization problem\n",
        "x1 = -0.1\n",
        "x2 = 0.1\n",
        "def myfunc(x1, x2):\n",
        "  return (x1 - 2)**2 + (0.5*x2 - 1.5)**2 - 3\n",
        "opt = Adam(learning_rate=0.1)\n",
        "\n",
        "x1g, x2g = np.meshgrid(np.linspace(-1, 4), np.linspace(-1, 4))\n",
        "plt.figure()\n",
        "plt.imshow(myfunc(x1g, x2g), extent=[-1, 4, -1, 4], origin=\"lower\")\n",
        "plt.colorbar()\n",
        "\n",
        "x1_history = np.zeros((100,1))\n",
        "x2_history = np.zeros((100,1))\n",
        "for i in range(100):\n",
        "  dx1 = 2*(x1 - 2)\n",
        "  dx2 = 2*(0.5*x2 - 1.5)\n",
        "  [[x1], [x2]] = opt(np.array([[x1], [x2]]), np.array([[dx1], [dx2]]))\n",
        "  x1_history[i] = x1\n",
        "  x2_history[i] = x2\n",
        "\n",
        "plt.scatter(x1_history, x2_history, c=range(100))\n",
        "plt.show()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.099]\n",
            " [2.199]\n",
            " [3.301]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3z-908mTNqP",
        "colab_type": "text"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VCmKK1mTR5M",
        "colab_type": "text"
      },
      "source": [
        "### Dense"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ufDoUVTT2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      shapes\n",
        "------------------\n",
        "w: (units_prev, units)\n",
        "b: (units, 1)\n",
        "X: (m, units_prev)\n",
        "z: (m, units)\n",
        "\n",
        "grads_upstream:   (m, units)\n",
        "grads_downstream: (m, units_prev)\n",
        "dw:               (units_prev, units)\n",
        "db:               (units, 1)\n",
        "vars:             (vars, 1)\n",
        "dvars:            (vars, 1)\n",
        "\"\"\"\n",
        "class Dense():\n",
        "  def __init__(self, units, kernel_initializer = \"xavier\", bias_initializer = \"zeros\"):\n",
        "    self.units = units\n",
        "    self.kernel_initializer = kernel_initializer\n",
        "    self.bias_initializer = bias_initializer\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "  \n",
        "  def __call__(self, X):\n",
        "    return self.forward(X)\n",
        "  \n",
        "  def get_weights(self):\n",
        "    return {\"weights\": self.w, \"biases\": self.b}\n",
        "  \n",
        "  def get_trainables_count(self):\n",
        "    count = 0\n",
        "    if self.w is not None:\n",
        "      count += np.prod(self.w.shape)\n",
        "    if self.b is not None:\n",
        "      count += np.prod(self.b.shape)\n",
        "    return count\n",
        "\n",
        "  def forward(self, X):\n",
        "    assert len(X.shape) == 2\n",
        "\n",
        "    if self.w is None:\n",
        "      if self.kernel_initializer == \"xavier\":\n",
        "        self.w = xavier((X.shape[1], self.units), (X.shape[1],))\n",
        "      elif self.kernel_initializer == \"zeros\":\n",
        "        self.w = zeros((X.shape[1], self.units))\n",
        "\n",
        "    if self.b is None:\n",
        "      if self.bias_initializer == \"xavier\":\n",
        "        self.b = xavier((self.units, 1), (1,))\n",
        "      elif self.bias_initializer == \"zeros\":\n",
        "        self.b = zeros((self.units, 1))\n",
        "    \n",
        "    self.X = X\n",
        "    self.z = np.dot(X, self.w) + self.b.T\n",
        "    \n",
        "    return self.z\n",
        "  \n",
        "  \"\"\"\n",
        "  @param grads_upstream: incoming grad with shape (m, units)\n",
        "  \"\"\"\n",
        "  def backward(self, grads_upstream):\n",
        "    assert grads_upstream.shape == self.z.shape\n",
        "    db = np.average(grads_upstream, axis = 0).reshape(self.b.shape)\n",
        "    dw = np.dot(self.X.T, grads_upstream) / self.X.shape[0]\n",
        "    grads_downstream = np.dot(grads_upstream, self.w.T)\n",
        "    vars = np.concatenate((self.w.reshape((-1, 1)), self.b))\n",
        "    dvars = np.concatenate((dw.reshape(-1, 1), db))\n",
        "    assert len(vars.shape) == 2\n",
        "    assert vars.shape[1] == 1\n",
        "    assert vars.shape == dvars.shape\n",
        "    return grads_downstream, vars, dvars\n",
        "  \n",
        "  def set_weights(self, vars):\n",
        "    assert vars.shape[0] == self.get_trainables_count()\n",
        "    assert vars.shape[1] == 1\n",
        "    assert len(vars.shape) == 2\n",
        "    self.w = vars[:np.prod(self.w.shape)].reshape(self.w.shape)\n",
        "    self.b = vars[-np.prod(self.b.shape):].reshape(self.b.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpM2Bmgwn8vx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "3c4679e0-29c0-41e7-a0c5-11d7fa04cdfb"
      },
      "source": [
        "X = np.array([[1, 2, 3], [1, 2, 3], [1, 2, 3], [1, 2, 3]])\n",
        "dense = Dense(2)\n",
        "\n",
        "dense(X)\n",
        "print(\"weights and biases: \\n\", dense.get_weights())\n",
        "stream, vars, dvars = dense.backward(np.array([[1, 1], [1, 1], [1, 1], [1, 1]]))\n",
        "print(\"\\ngradient stream: \\n\", stream)\n",
        "print(\"\\ndw db: \\n\", dvars)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "weights and biases: \n",
            " {'weights': array([[-0.00143974,  0.00844148],\n",
            "       [-0.01189423, -0.00186148],\n",
            "       [-0.00221734,  0.00654582]]), 'biases': array([[0.],\n",
            "       [0.]])}\n",
            "\n",
            "gradient stream: \n",
            " [[ 0.00700174 -0.0137557   0.00432848]\n",
            " [ 0.00700174 -0.0137557   0.00432848]\n",
            " [ 0.00700174 -0.0137557   0.00432848]\n",
            " [ 0.00700174 -0.0137557   0.00432848]]\n",
            "\n",
            "dw db: \n",
            " [[1.]\n",
            " [1.]\n",
            " [2.]\n",
            " [2.]\n",
            " [3.]\n",
            " [3.]\n",
            " [1.]\n",
            " [1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ftqf0rk8yi2u",
        "colab_type": "text"
      },
      "source": [
        "### ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C24-m-pUyqOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      shapes\n",
        "------------------\n",
        "X: (m, units)\n",
        "z: (m, units)\n",
        "\n",
        "grads_upstream:   (m, units)\n",
        "grads_downstream: (m, units)\n",
        "\"\"\"\n",
        "class ReLU():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "    \n",
        "  def __call__(self, X):\n",
        "    return self.forward(X)\n",
        "  \n",
        "  def get_trainables_count(self):\n",
        "    return 0\n",
        "  \n",
        "  def forward(self, X):\n",
        "    assert len(X.shape) == 2\n",
        "    self.z = np.maximum(X, 0)\n",
        "    assert len(self.z.shape) == 2\n",
        "    return self.z\n",
        "  \n",
        "  \"\"\"\n",
        "  @param grads_upstream: incoming grad with shape (m, units)\n",
        "  \"\"\"\n",
        "  def backward(self, grads_upstream):\n",
        "    assert len(grads_upstream.shape) == 2\n",
        "    assert grads_upstream.shape == self.z.shape\n",
        "    grads_downstream = grads_upstream * (self.z > 0)\n",
        "    assert len(grads_downstream.shape) == 2\n",
        "    assert grads_downstream.shape == self.z.shape\n",
        "    return grads_downstream, None, None\n",
        "  \n",
        "  def set_weights(self, vars):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGt3LGpL2Suj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "9fa6c8f8-7e00-41d3-e914-0ac4e7760678"
      },
      "source": [
        "X = np.array([[1, 2, 3], [1, -2, 3], [1, 2, -3], [1, 2, 3]])\n",
        "relu = ReLU()\n",
        "\n",
        "print(\"output: \\n\", relu(X))\n",
        "stream, vars, dvars = relu.backward(np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]))\n",
        "print(\"\\ngradient stream: \\n\", stream)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output: \n",
            " [[1 2 3]\n",
            " [1 0 3]\n",
            " [1 2 0]\n",
            " [1 2 3]]\n",
            "\n",
            "gradient stream: \n",
            " [[1 1 1]\n",
            " [1 0 1]\n",
            " [1 1 0]\n",
            " [1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHvC7gGQ9zHk",
        "colab_type": "text"
      },
      "source": [
        "### Softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yWVw_YM905o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      shapes\n",
        "------------------\n",
        "X: (m, units)\n",
        "z: (m, units)\n",
        "\n",
        "grads_upstream:   (m, units)\n",
        "grads_downstream: (m, units)\n",
        "\"\"\"\n",
        "class Softmax():\n",
        "  def __init__(self):\n",
        "    pass\n",
        "    \n",
        "  def __call__(self, X):\n",
        "    return self.forward(X)\n",
        "  \n",
        "  def get_trainables_count(self):\n",
        "    return 0\n",
        "  \n",
        "  def forward(self, X):\n",
        "    assert len(X.shape) == 2\n",
        "    self.z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape((-1, 1))\n",
        "    return self.z\n",
        "  \n",
        "  \"\"\"\n",
        "  @param grads_upstream: incoming grad with shape (m, units)\n",
        "  \"\"\"\n",
        "  def backward(self, grads_upstream):\n",
        "    assert len(grads_upstream.shape) == 2\n",
        "    assert grads_upstream.shape == self.z.shape\n",
        "    grads_downstream = grads_upstream * (self.z * (1 - self.z))\n",
        "    return grads_downstream, None, None\n",
        "  \n",
        "  def set_weights(self, vars):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0PvFSraBdgL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4b2f4676-6d95-48db-f5e9-5ff1f8f8d504"
      },
      "source": [
        "X = np.array([[3, 3, 3], [1, -2, 3], [1, 2, -3], [1, 2, 3]])\n",
        "softmax = Softmax()\n",
        "\n",
        "print(\"output: \\n\", softmax(X))\n",
        "stream, vars, dvars = softmax.backward(np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 1]]))\n",
        "print(\"\\ngradient stream: \\n\", stream)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output: \n",
            " [[0.33333333 0.33333333 0.33333333]\n",
            " [0.11849965 0.00589975 0.8756006 ]\n",
            " [0.26762315 0.72747516 0.00490169]\n",
            " [0.09003057 0.24472847 0.66524096]]\n",
            "\n",
            "gradient stream: \n",
            " [[0.22222222 0.22222222 0.22222222]\n",
            " [0.10445749 0.00586494 0.10892419]\n",
            " [0.196001   0.19825505 0.00487766]\n",
            " [0.08192507 0.18483645 0.22269543]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k17eyi3IJMRQ",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gR-BRK7lJPp3",
        "colab_type": "text"
      },
      "source": [
        "### Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6yOLtOXJbNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      shapes\n",
        "------------------\n",
        "layers:    list\n",
        "optimizer: class instance\n",
        "loss_func: func\n",
        "accuracy:  func or None\n",
        "\"\"\"\n",
        "class Sequential():\n",
        "  def __init__(self):\n",
        "    self.layers = []\n",
        "    self.optimizer = None\n",
        "    self.loss_func = None\n",
        "    self.accuracy = None\n",
        "  \n",
        "  def __call__(self, X):\n",
        "    return self.forward(X)\n",
        "\n",
        "  def add(self, layer):\n",
        "    self.layers.append(layer)\n",
        "\n",
        "  def forward(self, X):\n",
        "    for layer in self.layers:\n",
        "      X = layer(X)\n",
        "    return X\n",
        "  \n",
        "  def compile(self, optimizer='adam', loss='categorical_crossentropy', accuracy=None):\n",
        "    if optimizer == \"adam\":\n",
        "      self.optimizer = Adam()\n",
        "    if loss == \"categorical_crossentropy\":\n",
        "      self.loss_func = categorical_crossentropy\n",
        "    if isinstance(optimizer, Adam):\n",
        "      self.optimizer = optimizer\n",
        "    if accuracy == \"categorical_accuracy\":\n",
        "      self.accuracy = categorical_accuracy\n",
        "  \n",
        "  def fit(self, trainX, trainy, batch_size = 32, epochs = 1, validation_data = None, shuffle = True):\n",
        "    assert len(trainX.shape) == 2\n",
        "    assert len(trainy.shape) == 2\n",
        "    for i in range(epochs):\n",
        "      tic = time.time()\n",
        "      if shuffle == True:\n",
        "        trainX, trainy = self.__shuffle(trainX, trainy)\n",
        "      \n",
        "      train_loss = 0\n",
        "      train_acc = 0\n",
        "      for batch_start in range(0, len(trainX), batch_size):\n",
        "        batchX = trainX[batch_start: batch_start + batch_size]\n",
        "        batchy = trainy[batch_start: batch_start + batch_size]\n",
        "        t_loss, t_acc = self.__train_batch(batchX, batchy)\n",
        "        train_loss += t_loss\n",
        "        if t_acc is not None:\n",
        "          train_acc += t_acc\n",
        "      train_loss = train_loss / ((len(trainX)+batch_size-1)//batch_size)\n",
        "      train_acc = train_acc / ((len(trainX)+batch_size-1)//batch_size)\n",
        "      \n",
        "      if validation_data is not None:\n",
        "        assert len(validation_data[0].shape) == 2\n",
        "        assert len(validation_data[1].shape) == 2\n",
        "        yhat = self.forward(validation_data[0])\n",
        "        val_loss, _ = self.loss_func(validation_data[1], yhat)\n",
        "        if self.accuracy is not None:\n",
        "          val_acc = self.accuracy(validation_data[1], yhat)\n",
        "      \n",
        "      toc = time.time()\n",
        "      if validation_data is None:\n",
        "        if self.accuracy is None:\n",
        "          print(\"Epoch %d ended (in %.2fs): loss = %.4f\".format(i, toc-tic, train_loss))\n",
        "        else:\n",
        "          print(\"Epoch %d ended (in %.2fs): loss = %.4f    accuracy = %.4f\".format(i, toc-tic, train_loss, train_acc))\n",
        "      else:\n",
        "        if self.accuracy is None:\n",
        "          print(\"Epoch %d ended (in %.2fs): loss = %.4f    val_loss = \".format(i, toc-tic, train_loss, val_loss))\n",
        "        else:\n",
        "          print(\"Epoch %d ended (in %.2fs): loss = %.4f    accuracy = %.4f    val_loss = %.4f    val_accuracy = %.4f\" %\n",
        "                (i, toc-tic, train_loss, train_acc, val_loss, val_acc))\n",
        "\n",
        "  \n",
        "  def __shuffle(self, x, y):\n",
        "    assert len(x) == len(y)\n",
        "    p = np.random.permutation(len(x))\n",
        "    return x[p], y[p]\n",
        "  \n",
        "  def __train_batch(self, x, y):\n",
        "    yhat = self.forward(x)\n",
        "    loss, stream = self.loss_func(y, yhat)\n",
        "    accuracy = None\n",
        "    if self.accuracy is not None:\n",
        "      accuracy = self.accuracy(y, yhat)\n",
        "    vars = None\n",
        "    dvars = None\n",
        "    for layer in reversed(self.layers):\n",
        "      stream, var, dvar = layer.backward(stream)\n",
        "      if vars is None:\n",
        "        vars = var\n",
        "      elif var is not None:\n",
        "        vars = np.concatenate((vars, var))\n",
        "      if dvars is None:\n",
        "        dvars = dvar\n",
        "      elif dvar is not None:\n",
        "        dvars = np.concatenate((dvars, dvar))\n",
        "    assert len(vars.shape) == 2\n",
        "    assert vars.shape[1] == 1\n",
        "    assert vars.shape == dvars.shape\n",
        "\n",
        "    vars_changed = self.optimizer(vars, dvars)\n",
        "\n",
        "    for layer in reversed(self.layers):\n",
        "      trainables_count = layer.get_trainables_count()\n",
        "      layer.set_weights(vars_changed[:trainables_count])\n",
        "      vars_changed = vars_changed[trainables_count:]\n",
        "    \n",
        "    return loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpNuV-LMNgWU",
        "colab_type": "text"
      },
      "source": [
        "## Other stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCBWMauJNll1",
        "colab_type": "text"
      },
      "source": [
        "### to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2GETg6VNpSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_categorical(y):\n",
        "  min = np.min(y)\n",
        "  max = np.max(y)\n",
        "  ycat = np.zeros((y.shape[0], max-min+1))\n",
        "  for i in range(len(y)):\n",
        "    ycat[i, y[i]-min] = 1\n",
        "  return ycat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvgsgJVvS4et",
        "colab_type": "text"
      },
      "source": [
        "### categorical_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQfGUvPyS7BR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "      shapes\n",
        "------------------\n",
        "y, yhat: (m, units)\n",
        "\"\"\"\n",
        "def categorical_accuracy(y, yhat):\n",
        "  y = np.argmax(y, axis = 1)\n",
        "  yhat = np.argmax(yhat, axis = 1)\n",
        "  match = (y == yhat)\n",
        "  return np.sum(match) / len(match)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2AVwOgYTsK4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8bc9d731-eb6c-47ab-b7c3-e6cc8ba0bce4"
      },
      "source": [
        "a = [[0,   0,   1,   0,   0  ], [0,   0,   1,   0,   0  ], [0,   0,   1,   0,   0  ]]\n",
        "b = [[0.1, 0.2, 0.4, 0.1, 0.1], [0.1, 0.6, 0.2, 0.1, 0.0], [0.1, 0.1, 0.8, 0.0, 0.0]]\n",
        "print(categorical_accuracy(a, b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FiioFQSKD74",
        "colab_type": "text"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sssGk2bQKbFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "41191a3c-e33c-4726-8aa7-a7d0fd2c3ab8"
      },
      "source": [
        "(trainX_2d, trainy_int), (testX_2d, testy_int) = load_data()\n",
        "\n",
        "trainX = trainX_2d.reshape(trainX_2d.shape[0], -1)\n",
        "testX = testX_2d.reshape(testX_2d.shape[0], -1)\n",
        "\n",
        "trainy = to_categorical(trainy_int)\n",
        "testy = to_categorical(testy_int)\n",
        "\n",
        "trainX = trainX.astype(\"float32\")/255\n",
        "testX = testX.astype(\"float32\")/255\n",
        "\n",
        "# show a test\n",
        "plt.imshow(trainX_2d[2])\n",
        "print(trainy[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl53lh0vj7De",
        "colab_type": "text"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc96c1mILJEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10))\n",
        "model.add(Softmax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCbFiO9pUkQk",
        "colab_type": "text"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrgUFMovLgIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "outputId": "c18b8426-d061-4f7f-a1e6-ffbbedb8ae68"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(10))\n",
        "model.add(Softmax())\n",
        "opt = Adam(0.001)\n",
        "model.compile(optimizer = opt, loss = \"categorical_crossentropy\", accuracy = \"categorical_accuracy\")\n",
        "model.fit(trainX, trainy, epochs = 50, validation_data = (testX, testy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 ended (in 3.84s): loss = 1.8901    accuracy = 0.3366    val_loss = 1.8111    val_accuracy = 0.3746\n",
            "Epoch 1 ended (in 4.01s): loss = 1.7983    accuracy = 0.3736    val_loss = 1.8258    val_accuracy = 0.3547\n",
            "Epoch 2 ended (in 3.82s): loss = 1.7801    accuracy = 0.3803    val_loss = 1.8101    val_accuracy = 0.3636\n",
            "Epoch 3 ended (in 3.96s): loss = 1.7652    accuracy = 0.3887    val_loss = 1.7538    val_accuracy = 0.3889\n",
            "Epoch 4 ended (in 3.94s): loss = 1.7591    accuracy = 0.3912    val_loss = 1.7685    val_accuracy = 0.3823\n",
            "Epoch 5 ended (in 3.79s): loss = 1.7471    accuracy = 0.3974    val_loss = 1.7458    val_accuracy = 0.3892\n",
            "Epoch 6 ended (in 3.79s): loss = 1.7415    accuracy = 0.3972    val_loss = 1.8059    val_accuracy = 0.3750\n",
            "Epoch 7 ended (in 3.75s): loss = 1.7342    accuracy = 0.3991    val_loss = 1.7665    val_accuracy = 0.3771\n",
            "Epoch 8 ended (in 3.79s): loss = 1.7297    accuracy = 0.4025    val_loss = 1.7761    val_accuracy = 0.3788\n",
            "Epoch 9 ended (in 3.79s): loss = 1.7253    accuracy = 0.4058    val_loss = 1.7412    val_accuracy = 0.3914\n",
            "Epoch 10 ended (in 3.82s): loss = 1.7207    accuracy = 0.4069    val_loss = 1.7453    val_accuracy = 0.3898\n",
            "Epoch 11 ended (in 3.81s): loss = 1.7177    accuracy = 0.4093    val_loss = 1.7691    val_accuracy = 0.3873\n",
            "Epoch 12 ended (in 3.84s): loss = 1.7159    accuracy = 0.4099    val_loss = 1.7349    val_accuracy = 0.3953\n",
            "Epoch 13 ended (in 3.83s): loss = 1.7154    accuracy = 0.4085    val_loss = 1.7625    val_accuracy = 0.3866\n",
            "Epoch 14 ended (in 3.83s): loss = 1.7095    accuracy = 0.4123    val_loss = 1.7613    val_accuracy = 0.3822\n",
            "Epoch 15 ended (in 3.84s): loss = 1.7082    accuracy = 0.4140    val_loss = 1.7566    val_accuracy = 0.3833\n",
            "Epoch 16 ended (in 3.84s): loss = 1.7054    accuracy = 0.4116    val_loss = 1.7462    val_accuracy = 0.3895\n",
            "Epoch 17 ended (in 3.84s): loss = 1.7011    accuracy = 0.4166    val_loss = 1.7946    val_accuracy = 0.3698\n",
            "Epoch 18 ended (in 3.90s): loss = 1.7017    accuracy = 0.4141    val_loss = 1.7544    val_accuracy = 0.3915\n",
            "Epoch 19 ended (in 3.79s): loss = 1.6951    accuracy = 0.4197    val_loss = 1.7653    val_accuracy = 0.3881\n",
            "Epoch 20 ended (in 3.80s): loss = 1.6996    accuracy = 0.4159    val_loss = 1.7483    val_accuracy = 0.3957\n",
            "Epoch 21 ended (in 3.79s): loss = 1.6948    accuracy = 0.4173    val_loss = 1.7506    val_accuracy = 0.3924\n",
            "Epoch 22 ended (in 3.79s): loss = 1.6919    accuracy = 0.4201    val_loss = 1.7506    val_accuracy = 0.3917\n",
            "Epoch 23 ended (in 3.82s): loss = 1.6904    accuracy = 0.4215    val_loss = 1.7328    val_accuracy = 0.3980\n",
            "Epoch 24 ended (in 3.79s): loss = 1.6908    accuracy = 0.4202    val_loss = 1.7666    val_accuracy = 0.3872\n",
            "Epoch 25 ended (in 3.82s): loss = 1.6856    accuracy = 0.4222    val_loss = 1.7763    val_accuracy = 0.3820\n",
            "Epoch 26 ended (in 3.87s): loss = 1.6889    accuracy = 0.4195    val_loss = 1.7613    val_accuracy = 0.3866\n",
            "Epoch 27 ended (in 3.91s): loss = 1.6849    accuracy = 0.4200    val_loss = 1.7509    val_accuracy = 0.3957\n",
            "Epoch 28 ended (in 3.83s): loss = 1.6872    accuracy = 0.4220    val_loss = 1.7517    val_accuracy = 0.3892\n",
            "Epoch 29 ended (in 3.85s): loss = 1.6784    accuracy = 0.4272    val_loss = 1.7721    val_accuracy = 0.3818\n",
            "Epoch 30 ended (in 3.87s): loss = 1.6829    accuracy = 0.4239    val_loss = 1.7709    val_accuracy = 0.3832\n",
            "Epoch 31 ended (in 3.79s): loss = 1.6815    accuracy = 0.4232    val_loss = 1.7551    val_accuracy = 0.3898\n",
            "Epoch 32 ended (in 3.77s): loss = 1.6814    accuracy = 0.4235    val_loss = 1.7442    val_accuracy = 0.3966\n",
            "Epoch 33 ended (in 3.81s): loss = 1.6747    accuracy = 0.4263    val_loss = 1.7787    val_accuracy = 0.3804\n",
            "Epoch 34 ended (in 3.84s): loss = 1.6775    accuracy = 0.4262    val_loss = 1.7744    val_accuracy = 0.3844\n",
            "Epoch 35 ended (in 3.83s): loss = 1.6772    accuracy = 0.4249    val_loss = 1.7353    val_accuracy = 0.4034\n",
            "Epoch 36 ended (in 3.94s): loss = 1.6762    accuracy = 0.4254    val_loss = 1.7690    val_accuracy = 0.3888\n",
            "Epoch 37 ended (in 3.97s): loss = 1.6741    accuracy = 0.4263    val_loss = 1.7899    val_accuracy = 0.3698\n",
            "Epoch 38 ended (in 3.90s): loss = 1.6731    accuracy = 0.4278    val_loss = 1.7384    val_accuracy = 0.3994\n",
            "Epoch 39 ended (in 3.80s): loss = 1.6766    accuracy = 0.4244    val_loss = 1.7304    val_accuracy = 0.4043\n",
            "Epoch 40 ended (in 3.78s): loss = 1.6708    accuracy = 0.4285    val_loss = 1.8093    val_accuracy = 0.3761\n",
            "Epoch 41 ended (in 3.81s): loss = 1.6733    accuracy = 0.4247    val_loss = 1.7530    val_accuracy = 0.3922\n",
            "Epoch 42 ended (in 3.80s): loss = 1.6725    accuracy = 0.4300    val_loss = 1.7777    val_accuracy = 0.3835\n",
            "Epoch 43 ended (in 3.84s): loss = 1.6707    accuracy = 0.4277    val_loss = 1.7518    val_accuracy = 0.3957\n",
            "Epoch 44 ended (in 3.78s): loss = 1.6670    accuracy = 0.4296    val_loss = 1.7560    val_accuracy = 0.3875\n",
            "Epoch 45 ended (in 3.84s): loss = 1.6680    accuracy = 0.4285    val_loss = 1.7719    val_accuracy = 0.3826\n",
            "Epoch 46 ended (in 3.84s): loss = 1.6666    accuracy = 0.4301    val_loss = 1.7438    val_accuracy = 0.4008\n",
            "Epoch 47 ended (in 3.80s): loss = 1.6657    accuracy = 0.4303    val_loss = 1.7627    val_accuracy = 0.3874\n",
            "Epoch 48 ended (in 3.83s): loss = 1.6661    accuracy = 0.4297    val_loss = 1.7494    val_accuracy = 0.3924\n",
            "Epoch 49 ended (in 3.88s): loss = 1.6642    accuracy = 0.4291    val_loss = 1.7573    val_accuracy = 0.3808\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}